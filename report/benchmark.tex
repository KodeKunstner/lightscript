\chapter{Benchmarks}
\label{benchmark}

\section{Code footprint}
This section looks at the code footprint: first footprint estimates are compared for different scripting languages, then details on the footprint of LightScript is investigated, and finally the actual size of the library embedded in a minimal application is found.

\subsection{Comparison with other languages}
To compare the code footprint size across languages, I have added an estimate of the jar file size. 
The estimate is done by making a zip archive of the non-obscurified class files,
trying to exclude class files that are part of extra libraries.
The motivation for this approach is to make the comparison more fair, as some of the languages have large GUI libraries,
which would count against them, if we just looked at the jar file. 
In addition, compilation of some of the languages is obscurified/optimised by default,
which would give those an advantage. So this should give a more fair comparison.

\subsubsection{Languages}
\label{codefootprint-languages}
The code size benchmark looks at the languages implemented in this project, Yolan and LightScript, it looks at scripting languages for mobile devices, FScriptMe, Kahlua, Hecl, Simkin, and CellularBasic, and it looks at some general scripting language implementations,  JScheme, and Rhino.

FScriptME\cite{fscriptme} is the mobile edition of femto-script, which ``is an extremely simple scripting language''\cite{fscript}. 
Out of the box, it only supports strings and integers as datatypes -- no compound types -- which limits use somewhat, and it is still in beta, since 2002. 

JScheme\cite{jscheme} is a small Scheme implementation. It depends on some reflection, and does therefor not run on Java Mobile Edition, but is included as the implementation is compact, and may be possible to target mobile devices.

Kahlua\cite{kahlua} is an implementation of the Lua Virtual Machine for Java Mobile Edition. 
The implementation requires CLDC-1.1 due to the use of floating point arithmetics, and does therefor not run on the lowest end mobile devices, which only supports CLDC-1.0.
Unlike the other languages, kahlua is not a full language interpreter, but only a virtual machine, so the the script cannot executed directly on the device, but needs to be compiled on another computer before being executed.

Hecl\cite{hecl} seems to be \emph{the} major scripting language for mobile devices, or at least the one keep popping up in the top of most queries when searching for scripting languages for mobile devices.
It is very portable, with different editions running on CLDC-1.0, CLDC-1.1, Android, as applets and as usual applications.
It has lots of libraries targeting mobile devices, which in this comparison were removed from the zip file of class files, not to give languages with fewer libraries an advantage in the size comparison.
The language is a dialect of Tcl, and is simplified such that arithmetic operators, and the like, are prefix operators so expressions ends up a bit lisp-like.

Simkin\cite{simkin} is a scripting language for being embedded in XML. The depends on kxml xml library, which is not included in the measured size. 

CellularBasic\cite{cellularbasic} is a dialect of Qbasic, implemented for mobile devices. 
It includes a floating point support library which is not included in the measured size. 

Rhino\cite{rhino} is a JavaScript implementation. This language is not designed for, nor does it run on, mobile devices. It is included as an example of an implementation of a usual non-mobile scripting language.

\subsubsection{Results}
The approximated JAR sizes of the scripting languages are:
\begin{center}
\begin{tabular}{|c|r|} \hline 
Yolan & 7K \\ \hline 
LightScript & 14K \\ \hline 
\end{tabular}
\begin{tabular}{|c|r|} \hline 
FScriptME & 17K \\ \hline 
Jscheme & 29K \\ \hline 
Kahlua & 39K \\ \hline 
Hecl & 54K \\ \hline 
Simkin & 81K \\ \hline 
CellularBasic & 83K \\ \hline 
Rhino & 397K \\ \hline 
\end{tabular}
\end{center}

The languages developed in this project smaller than other scripting languages for the platform. 
Yolan is approximately half the size of LightScript. 

\subsection{Details on the footprint of LightScript}
The sizes of the different part of the LightScript class is listed below.
Reduction is the reduction of the full class file when the mentioned part is left out. Alone is the size of the class file with everything else than the mentioned part left out. These numbers are different as some things are shared and some things cannot be left out when compiling the class file.

\begin{center} \begin{tabular}{|r|r|rl|} \hline
\multicolumn{2}{|r|}{Reduction} & \multicolumn{2}{|l|}{Alone}\\ \hline
Everything & 15030 & 17706 & \\ \hline
API & 645  & 3597  & \\ \hline
Tokeniser & 1261 & 4048 & \\ \hline
Parser & 2542 & 5850 & \\ \hline
Compiler & 5324 & 8413 & \\ \hline
Vm & 4589 & 7650 & \\ \hline
Parser+Tokeniser & 3825 & 7093 & \\ \hline
\end{tabular} \end{center}

\subsection{Optimised JAR-file footprint}
Previous sections have looked at comparable footprints for implementations by approximated JAR file size, and also at what parts contributes to the size of the LightScript class.
From a practical view it is also interesting to see the actual size of the optimised obscurified JAR-file of embedding the languages in a trivial host application.
The host application is a simple Midlet that adds a print function to the language, and includes a hello-world program.
The size of the entire application, including the embedded scripting language implementation is 5290 bytes for Yolan and 11279 bytes for LightScript. 

\section{Execution speed}
This section benchmarks the execution speed of the languages. 
In the following subsections, the languages that are benchmarked, and the actual benchmark programs are described.
The source code for the benchmarks can be seen in appendix~\ref{benchmarksource}.
The results of the benchmarks can be seen in figure~\ref{figure-execution-speed}.

\subsection{Languages}
The benchmarks are run on those of the languages from section~\ref{codefootprint-languages}, that have an approximated jar size of less than 64K. They also run on two JavaScript interpreters: Rhino 1.6r7 and SpiderMonkey 1.7.0, which are described in section~\ref{spidermonkey}, and are the default versions when installed on Ubuntu Linux.

\subsection{The benchmarks}
The benchmarks are the following:

\paragraph{Fibonacci:} Recursive calculation of the 30'th Fibonacci number
\paragraph{Loops:} Nested loops with counters, 10.000.000 iterations
\paragraph{Recursion:} Highly recursive benchmark, similar to recursive control-flow benchmark from \cite{sunspider, shootout}. Uses lots of stack space. On some of the languages where it fails, only the first part of it was implemented.
\paragraph{Sieve:} Simple implementation of Erasthones sieve - not implemented in languages which have already shown to be very slow in earlier benchmarks
\paragraph{For-in:} Nested loops across keys of a dictionary, 1.000.000 iterations - not implemented in languages which have already shown to be very slow in earlier benchmarks
\paragraph{Primes:} Simple primality test by looking at the remainders of division - not implemented in languages which have already shown to be very slow in earlier benchmarks
\paragraph{Exception:} Throw/catch 500.000 exceptions - only implemented for LightScript/JavaScript
\paragraph{Fannkuch:} Access-fannkuch benchmark from \cite{sunspider, shootout} - only implementd for LightScript/JavaScript

\subsection{Results}
The measurement of the performance of the different scripting languages are shown below. The timings are seconds per benchmark. $\bot$ indicates that the benchmark does not complete due to running out of stack space.

\begin{center} \begin{tabular}{|r|r|r|r|r|r|r|r|rr|} \hline 
& \multicolumn{2}{|l|}{Fibonacci} & \multicolumn{2}{|l|}{Recursion} & \multicolumn{2}{|l|}{For-in} & \multicolumn{2}{|l}{Exceptions} & \\
& & \multicolumn{2}{|l|}{Loops} & \multicolumn{2}{|l|}{Sieve} & \multicolumn{2}{|l|}{Primes} & \multicolumn{2}{|l|}{Fannkuch} \\
\hline Rhino       & 1.20 & 1.74 & 1.75   & 2.97 & 1.18 & 12.35 & 45.99 & 6.35 & \\ 
\hline SpiderMonkey& 1.28 & 1.71 & $\bot$ & 2.08 & 1.14 & 11.03 & 0.45  & 5.10 & \\ 
\hline LightScript & 1.37 & 3.45 & 2.35   & 1.19 & 0.57 & 11.70 & 0.65  & 11.15 & \\
\hline Yolan       & 1.47 & 2.23 & $\bot$ & 1.95 & 0.32 &  9.20 &  &  & \\
\hline Kahlua      & 2.13 & 1.18 & $\bot$ &  5.73 & 2.26 & 5.49 &  &  & \\ 
\hline JScheme    & 29.77 & 93.22 & $\bot$ & & & & & & \\ 
\hline FscriptME & 176.27 & 112.68& $\bot$ & & & & & & \\ 
\hline Hecl      & 207.96 & 47.21 & $\bot$ & & & & & & \\ 
\hline \end{tabular}
\end{center} 

\section{Summary}
