\documentclass[11pt]{report} 
\usepackage{a4} 
%\usepackage[paperheight=220mm,paperwidth=170mm]{geometry}
%\usepackage[paperheight=150mm,paperwidth=200mm]{geometry}
\usepackage{geometry}
\usepackage{makeidx}
%\usepackage[danish]{babel} 
\usepackage[utf8]{inputenc}
\usepackage{textcomp}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{graphicx} 
\usepackage{verbatim} 
\usepackage{fancyhdr}
\usepackage{listings} 
%\usepackage[colorlinks,pagebackref]{hyperref}
\usepackage[colorlinks, linkcolor=black, anchorcolor=black, citecolor=black, menucolor=black, pagecolor=black, urlcolor=black]{hyperref}
%\usepackage{backref}
\usepackage{url}
\frenchspacing
\makeindex
\pagestyle{plain}
\lstset{language=java}
\lstset{escapeinside=`'}
\lstset{basicstyle=\scriptsize}

\title{
Design and Implementation of \\
a Scripting Language \\ 
for Mobile Devices \\
{\scriptsize version \input{version}}}

\author{
  Rasmus Jensen\footnote{
    rasmus@lightscript.net
  }
} 

% Remember 
%    \index terms
%    update template as well as document when structural updates.
\date{2009}

\begin{document}

\maketitle
\begin{abstract}
This thesis creates two new languages: LightScript and Yolan, which run on top of Java Micro Edition and enable scripting on very low-end mobile devices.

The code footprint is the major limitation on low end mobile devices, and both languages have a significantly smaller code footprint than existing scripting languages. 
The languages are comparable in speed to larger scripting language implementations,
and an order of magnitude faster than most of the benchmarked scripting languages for mobile devices.

Both scripting languages have first class functions, dynamic typing, built-in support for hashtables, stacks, etc., and support interactive programming. They are also able to load and execute scripts presented in source form at run-time. 
The Java Micro Edition does not support dynamic loading of code, so both languages are interpreted.
\index{Java Micro Edition}

LightScript is a subset of JavaScript; it is static scoped, and also includes support for objects and exceptions. It is compiled to, and executed on, a stack-based virtual machine. One of things that makes the compact implementation possible is that the LightScript parser is an imperative optimised version of the top-down operator precedence parser.
\index{scope}

Yolan is highly optimised for reducing the size of the implementation code footprint. It has dynamic scope, a Lisp-inspired syntax, and is interpreted by evaluating each node of the syntax tree.

Yolan has a code footprint less than half the size of LightScript, and they are similar in speed, even though they have very different evaluation strategies.
\end{abstract}

\setcounter{tocdepth}{1}
\tableofcontents

\chapter{Introduction}

    The topic of the project is to design and implement a scripting language
that runs on very low-end mobile devices. This is both to create a practical tool, and
also a focus for exploration of programming language theory. 

\begin{comment}
The motivation is that a scripting language makes it is easier to make applications for mobile 
devices, and that existing freely available scripting languages
are very limited, slow, or simply does not run on the low-end mobile devices.
\end{comment}

    The educational goals are to learn about programming language design and
implementation, and to learn about programming on mobile devices. Through the
project, I should be able to evaluate and choose programming language features
and implementation techniques, and design and implement a scripting language.

    The focus of the language is that it should be portable, embeddable and have
a low memory footprint. Portable implies that it should run on different devices,
from very low-end mobile phones to high-end computers, possibly also within a web browser. 
Embeddable implies that it should be easy to include within and interface with
other applications. Low memory footprint implies that it should be suitable for
running on platforms where the available memory is measured in kilobytes rather
than megabytes. 

    The approach will be pragmatic and favor simplicity.

\section{Motivation}
\index{Goals}
Scripting languages make it easier to write applications \cite{scripting-ousterhout}. Beside higher productivity, they also opens up for user based scripting and scriptable configurations.
On more powerful devices, ranging from high-end smartphones to personal computers, there are very good scripting languages available.
\index{Smartphones}
Scripting language implementations usually take a lot of resources, which is a problem on low-end mobile devices. On those devices, implementations may not be available, may be very slow, or have limitations, such as they cannot be executed directly, but need to be compiled on another machine, or they do not have basic data types.
The focus on a better implementation of scripting languages for mobile devices is thus a niche, where the result may actually be of practical use.

The focus on low-end devices also has another benefit:
it broadens the number of devices on which the language may run.
While very low-end devices are becoming uncommon in Denmark,
they still live on in countries with less information technology penetration.
Thus,  by targeting very low-end devices, 
this project may make scripting, and thus easier content creation,
more available,
and thus could be the beginning of a stepping stone 
towards more information and computing literacy.
The restrictions of low end mobile devices also imposes challenges, that may lead to interesting solutions.

\begin{comment}
From a personal point of view, 
I would like to get started on development for mobile devices, 
and would also like to brush up on programming language implementation.
Design and implementation of a scripting language for mobile devices is spot on this topic.
\end{comment}


\section{The structure and content of the report}

This first chapter is an introduction to the project, defining the methodology and overall direction. 
The second chapter is a survey topics related to the projects. This contains the background for decisions on platform, programming optimisations, language ideas gotten from other languages, and language implementation techniques.
The third and the fourth chapter documents two scripting languages developed through this thesis: Yolan and LightScript. This contains design choices for the languages, implementation details, descriptions of the languages themselves, and developer guides for embedding and using the languages.
The fifth chapter benchmarks benchmarks the developed languages against other scripting languages,
and the sixth and seventh chapter is discussion and conclusion of the work.

The appendix contain the source code for the core Yolan and LightScript class.

\section{Approach}
\label{method}

When making projects, the approach can be
more or less bottom-up or top-down.
A top-down approach could be like the waterfall model \cite{waterfall} of software development,
where we start with the specification, design and then implementation and test.
The bottom-up approach could be like stepwise refinement \cite{stepwise-refinement}, more agile \cite{agile-manifesto, extreme-programming}, starting out with a quick prototype, which gets more and more refined.

The purpose of this project is to learn about programming languages and mobile development, and create a scripting language. 
The bottom-up approach is chosen, as it opens more up for experimentation, and new ideas are easier follow, than with the top-down approach.

The methodology of the project was to start out with a series of experimental prototypes related to mobile scripting language implementation, while surveying the field. 
The best parts of the prototypes were then expanded and built further on, to create the actual scripting language.
Obsoleted prototypes include a Forth-like language, several parser/compiler implementations on top of EcmaScript, a couple of virtual machines on the JVM, some experiments towards an implementation in C, experiments with mobile applications and their GUI, and drafts of parts of what became LightScript and Yolan.


\chapter{Survey}
\label{survey}
The survey first looks at different mobile platform, to determine the target platform for the language. 
The platform turns out to be Java Micro Edition, and the next part of the survey then looks into implementation methods for that platform.
The following section then surveys other languages related to scripting and low end devices, and the final section looks into implementation techniques relevant for the scripting language implementation on top of the choosen platform.

\section{Mobile platforms}
\index{Mobile platforms}
This section surveys the different development platform for mobile devices, to determine a target platform for the language.
Mobile devices ranges from low end phones, which, if they are programmable at all, only support Java Micro Edition, up to advanced smartphones with performance resources similar to older desktop computers.
\index{Java Micro Edition}

Most low end phones support some kind of Java midlets\footnote{A midlet is a small Java application targeting mobile devices, similar to applets, which are small Java applications targeting web browsers}.
Here there are different APIs and device profiles, but the basic execution and deployment model is the same for devices that support midlets.

Low end devices rarely support loading of native code, and higher end devices may require various kinds of code signing to allow native programs to be distributed.

Besides Java and native code, JavaScript is becoming a potential language for applications for high end phone. \index{EcmaScript}
This is both due to its integration with the web, which means that it will be available on the phones with advanced browsers, due to the increased amount of memory on high end phones
and due to recent major performance advances within the JavaScript implementations, which are propagating towards mobile devices.

\subsection{Embedded systems}
\index{Embedded systems}

%The personal computers, PCs, as we know them, are only a very small fraction of the computers in use.
%Billions of electronic devices nowadays have small embedded computers; they are in mobile phones, kitchen equipment, washing machines, music instruments, car, even advanced greeting cards. 
%These embedded computer systems vary tremendously, from low end micro controllers with memory measured in bytes, up to powerful CPUs with vector processing units and many megabytes of memory.
%
%\subsubsection{Machine architecture}
%There are two significantly different classes of computers: The Harvard architecture, and the von Neumann architecture. The difference is whether the program code is in the same memory as the data or if they are separated.
%
%Larger computers usually use the von Neumann architecture where program and data are in the same memory, and this is the most commonly known model.
%On small micro controllers on the other hand, the data memory is usually separated from the program memory, which is what is called the Harvard architecture. 
%These two approaches to architecture date back to some of the early computers: the Harvard Mark I \cite{harvard-mark1} and the EDVAC \cite{edvac} by John von Neumann.
%
%On small micro controllers, programs are usually stored in flashable ROM, and on the Harvard architecture the separation of data and code makes it easier and cheaper to build the micro controller. For example, the size of the code words can be independent of the size of the data words.
%These may have less than a kilobyte of RAM, and some kilobytes of possibly flashable ROM for the executable code. Examples of this are the PIC-processors \cite{picspec}, or the ATmega 8-bit microcontrollers \cite{atmegaspec}.
%An interesting operating system for low end devices is Contiki \cite{contiki}, which also demonstrate how very lightweight threads can be implement.
%
%On more powerful embedded devices, for example mobile phones, and larger computers,
%it may sometimes be practical to be able to work with the code as data, and thus the von Neumann architecture makes more sense there.
%For mobile and larger embedded devices a typical CPU architecture is the ARM \cite{arm-architecture}, which is a 32 bit RISC architecture.
%
%\subsubsection{Development platform}

%While embedded systems are very very common, the software is a shipped, or possibly flashable updateable on larger system, but there are generally no support for software development.
Low- to mid-end mobile phones are just another kind of embedded devices, where high-end phones are getting closer to being personal computers.
One thing that characterises embedded systems is that the software is a shipped with the devices, and there are no or low support for software development.
So while there are support for execution of midlets, native applications are not immediately possible to develop, unless you are also a hardware developer.

There are ways to experiment with development for low end devices nonteheless:
Some devices are hackable in the sense that somebody has found out how to upload and customise the firmware, usually without documentation and support from the manufacturer -- examples here ranges from digital cameras, mobile phones and handheld gaming devices.
A few devices opens up for development.

\index{Mindstorm NXT}
An interesting case here is the Lego Mindstorm NXT, which has hardware similar to low end mobile phones, except for the sound and GSM. 
The hardware contains an 48MHz ARM cpu\cite{arm7tdmi}, which is the same that is used in many mobile devices, 256KB of ROM, and 64KB of RAM, plus a coprocessor, a low resolution small display and a couple of buttons. \index{ARM cpu}
This may be used for prototyping an implementation of the scripting language, targeting embedded devices, although this will be postponed until a stable version on top of Java Mobile edition is done.


%So usually access to debug boards and expensive hardware is needed to get experiment with embedded devices, if possible at all.
%Another approach is that some devices is hackable in the sense that somebody has found out how to upload and customise the firmware, usually without documentation and support from the manufacturer -- examples here ranges from digital cameras, mobile phones and handheld gaming devices.
%A case on small embedded devices, where the manufacturer has actually opened up for development is the Lego brick that is a part of the Lego Mindstorm NXT, which will be elaborated in the next section.
%On larger devices it happens more often, though it is still rare: two smartphones \cite{openmoko, htc-android}, an E-book-reader, and some wireless routers and network attached storage \cite{wrtg, nslu, buffalo} have also opened, or partly opened, up for development.
%
%The Lego Mindstorm NXT is interesting because it is an easy to get started with embedded development platform. 
%The main cpu is an ARM7TDMI \cite{arm7tdmi}, which is commonly used in mobile phones, and also in many other embedded devices. 
%It is clocked at 48MHz, and is attached to 256 KB of flashable ROM and 64 KB of RAM, which means that it is low end, compared to mobile phones, while powerful viewed as an embedded device.
%There is also an ATmega48 \cite{atmega48} 8-bit coprocessor, which has 4KB of flashable ROM and 512 bytes of RAM, which is a typical microcontroller. 
%The coprocessor usually reads sensors, controls motors, and can power the main cpu down, to reduce power usage.
%The system also have a 100x64 black/white lcd display, and a couple of buttons, so it has a lot of potential as a development substitute platform for low-end mobile devices, which do not allow 3rd party firmware.
%
%So while there are no low end mobile phone which opens up for development, the Mindstorm NXT has similar specs, and can thus be a prototype target for an implementation targeting this class of devices.

\subsection{The J2ME / Java Micro Edition}
\index{Java Micro Edition}
\index{J2ME|see{Java Micro Edition}}

J2ME (Java Micro Edition\footnote{Java Micro Edition is a recent rebranding of J2ME}) is the most common platform for mobile application, supported by more than a billion devices \cite{sun-j2me}. 
It seems like two thirds of mobile phones shipped today supports Java \cite{esmertec-globenews}. 
\index{Mobile platforms!marketshares}
%http://www.globenewswire.com/newsroom/news.html?d=149713
Most mobile devices either require strict code signing, or do not allow native applications to be loaded at all, implies that J2ME is often the only option for mobile application development.
J2ME is a trimmed down Java Virtual Machine (JVM) so it has most of the features and limitations of a standard Java JVM, with some notable exceptions, such as the lack of dynamic class loading and reflection. It is a heterogenous platform:
there are different APIs/extensions from different vendors, and different device profiles for different hardware capabilities, meaning that the applications need to be ported.

Applications for J2ME, are called Midlets and are distributed via JAR-files (Java ARchive). A JAR file is essentially a zip file containing the compiled Java classes, data files, and some meta information.

J2ME has two device configurations CLDC 1.0 (Compact Limited Device Configuration 1.0) \cite{cldc10}  and CLDC 1.1  \cite{cldc11}. The major difference between the two is that CLDC 1.0 is integer only, whereas CLDC 1.1 supports floating point numbers.
It seems like approximately $\frac{1}{6}$ of the mobile phones that supports J2ME is limited to CLDC 1.0, whereas CLDC 1.1 is supported by the remaining $\frac{5}{6}$ of the phones \cite{mobref}.
% http://stats.getjar.com/statistics/world/gJavaCLDCVer
A limitation of both CLDCs is that they lack of support for reflection and dynamic code loading.
The lack of a reflection API impacts a scripting language in that it cannot discover native functions. This means that foreign function interface between Java and a scripting language, cannot discover or work with Java dynamically, but Java functions that should be callable from the scripting language must be coded into the implementation before deployment.
The lack of run-time class loading means that JIT compiling to JVM is not possible.
Neither is native code available, so the only way to execute scripts loaded at run-time is through interpretation, possibly via a virtual machine.

The CLDCs are based upon the Java JVM \cite{jvmref}, with some instructions removed, and some metadata added to ensure stack discipline. 
In order to simplify the J2ME JVM implementation, Java class files have to be preverified, before they can be loaded.
The preverification adds meta data about stack use, and removes certain instructions, such as local jump-and-save-register, to make it easier to implement a JVM that is safe against malicious code trying to overflow the stack.
The reference implementation of CLDC 1.0, KVM, is a switch-based interpreter with a compacting mark-and-sweep garbage collector \cite{kvm}.

The JVM limits interpreter implementation: it does not support label references as values, nor does it support functions as values. This makes some of the optimisations discussed in 
Section~\ref{interpreter-implementation} impossible.
Instead, it does have a builtin switch opcode as well as support for method-dispatch based on the type of an object, so an interpreter would either have to be switch-based, or have a class for every opcode.

The resources available for J2ME applications on mobile phones start at 64KB for the size of the JAR-file and 200KB for the run time memory on the lowest end devices, and goes upwards from there \cite{nokia-optim}.
These numbers are for the full application, so the resources available for an embeddable scripting language, could be significantly less than this, depending on the resource usage of the host application.

As Java Micro Edition is the most widespread platform for mobile devices, this will be the first target platform for the scripting language.

\subsection{Smartphones}
\index{Smartphones}
Many high end phones -- smartphones --  allows loading of native code. 
This covers approximately 12\% of the mobile phone market measured in number of units\footnote{In the fourth quarter of 2008 38.1 million smartphones where sold \cite{gartner}, whereas the total number of mobile phones sold in the same period were 314.7 million devices \cite{cellular-news}.}.
\index{Mobile platforms!marketshares}
% http://www.cellular-news.com/story/36315.php
Smartphones gives more access to the devices, than J2ME, but is at the same time more difficult to devlop for, due to the large number of platforms, and limits on distribution, which usually also requires cryptographical signing of code.

The main operating systems for smartphones are: Symbian, RIM, Windows Mobile, Mac OS X and Linux, which are very different operating systems, and even within the operating systems, there may be different user interfaces and programming models.
An important thing to notice is, development is not only possible as native applications, but many of the devices also support J2ME or other Java implementations, and on those devices that include a modern web browser, JavaScript is also a possibility for application development.

This means that if the scripting language is implemented on top of Java, then it will also run on many smartphones.  An aspect here is that some devices only supports other Java dialects that Java Micro Edition, so that should be kept in mind when developing the language. In addition, if the developed scripting language is a subset of JavaScript, it will already have an implementation deployed on those devices with advanced browsers.

%\subsubsection{Symbian}
%
%Symbian is the classical operating system for smartphones. Applications are usually written in C/C++, with some restrictions to allow it to run better on with a moderately small amount memory. 
%In order to distribute native applications on Symbian, it has to be cryptographically signed \cite{symbiansigned}.
%Symbian is a currently closed source, but is on its way to be released as open source \cite{symbianopensource}.
%
%It is the most popular operating system for smartphones, having 47.1\% of the market \cite{gartner-phone-survey-2008q4}. There are different incompatible user interfaces on top of Symbian, e.g. UIQ, QT, S60. 
%
%\subsubsection{RIM, Windows Mobile and Mac OS X}
%
%RIM (Research In Motion), Microsoft Windows Mobile and Mac OS X are the second to fourth most popular smart phone operating system, with 19.5\%, 12.4\% and 10.7\% market share respectively \cite{gartner-phone-survey-2008q4}.
%RIM is connected with the BlackBerry devices, Mac OS X is connected with the iPhone, and Windows Mobile covers different hardware vendors. 
%All these system are properitary closed source.
%
%\subsubsection{Linux}
%
%Linux has 8.4\% of the market share of smart phone operating systems.
%While most of these are properitary systems, two promising initiatives are opening up, wnad while they do not any significant market share yet, they are interesting from a developer point of view, and described below. These are the Android platform and the Openmoko project.
%
%
%\paragraph{Android}
%
%Android is a software stack for smartphones. It is open source, and driven forward by google.
%It is build upon a linux kernel, but user applications are not distributed natively, but executed on the Dalvik vm. Applications are written in Java, which is then compiled to Dalvik vm, rather than the usual JVM. The motivation for this is both to overcome some of the shortcomings of the JVM on mobile devices, and possibly also some cooperate issues with ownership of JVM technology.
%Beside supporting Dalvik applications, there is also a modern webbrowser -- a WebKit derivative -- meaning that JavaScript can also be executed on the device.
%
%While the software stack itself is open source, it also allows the manufactorer to make and keep proparitary changes for themselves. 
%Meaning that actual phones designed with the stack -- at least those currently on the market -- are not truely open, in the sense that thay contain properitery drivers and special developer-versions of the phones are needed if you want to be able to load customised operating system images/native code.
%
%Android is of course being ported to the devices from the Openmoko project, and in that case it is of course truely open.
%
%\paragraph{Openmoko}
%Openmoko is a project towards having open source phones.
%It is both a software stack for smartphones, and it is also a small development division of the hardware company FIC, where they are making the first open source phones.
%The two phones released so far have lots of rough edges both software and hardware wise, but from a developer point of view, these very interesting as they are not just phones but full Linux computers with X11 and most things as known from larger scale Linux environments -- and the source code is available for everything, so it is even possible to write new operating systems for them, and customise them in every way.
%
%

\section{Optimising Java for low end mobile devices}
The next to sections looks into methods of reducing the memory usage and code footprint of Java midlets.
These are very limited resources on some mobile devices, especially the code footprint, and techniques for optimising these will be needed when implementing the language.

\subsection{Reducing the memory usage of J2ME applications}

Some devices only have little memory available,
and an optimisation here is to be able to avoid having memory intensive parts of the program run at the same time. For example, with a scripting language, it is desirable to be able to garbage collect the executed parts of long script when they are done, so that the memory becomes available for other computations.
The usual size optimisations, such as finding compact representations, trimming dynamic data structures, avoiding sparse data, etc., are also applicable.
Here may be a tradeoff between the code footprint and run time memory, as compact representations and other optimisations may require more code to be implemented.

\subsection{Reducing the footprint of J2ME applications}
Some optimisations to reduce the code or JAR-file footprint:
\begin{itemize}
\item Reduce the number of class-files.
\item Write initialisation manually, where the automatic generated initialisation is inefficient.
\item Use a JAR-optimiser/obscurifier.
\item Put the classes in the unnamed package.
\end{itemize}

Another optimisation is to reduce the number of classes \cite{nokia-optim, kahlua-thesis}.
This may reduce the size of the JAR file significantly,
even though it does not change the amount of code:
Each class file has its own symbol table, which means that if classes are merged, then common symbols only need to be represented once, rather than once for each class.
Furthermore JAR files are essentially zip-archives, and each file in a zip archive is compressed individually \cite{zipspec}, which means that small files typically get compressed less than larger files, due to the small compression context.
The downside of reducing the number of classes is that it could go against the object oriented design, and the implementation scripting language may more difficult to read and edit. 

Initial values are not supported directly by the Java class file format, but instead
JVM-code is generated, that does the initialisation. 
This code is often inefficient. For example the initialisation:
\begin{verbatim}
byte[] bytes = { 1, 4, 3, 4, 5, 6, 2, 3, 1 } ;
\end{verbatim}
generates the code corresponding to
\begin{verbatim}
byte[] bytes = new byte[9];
bytes[0] = 1; bytes[1] = 4; bytes[2] = 3;
bytes[3] = 4; bytes[4] = 5; bytes[5] = 6;
bytes[6] = 2; bytes[7] = 3; bytes[8] = 1;
\end{verbatim}
which for a larger initialisation is significantly more expensive than the following manually written initialisers:
\begin{verbatim}
byte[] bytes = "\001\u004\u003\u004\u005\u006\u002\u003\u001".getBytes();
\end{verbatim}

Another thing to be aware of is that strings in Java class files are encoded such that only characters with unicode values between 1 and 127 (inclusive) use one byte per character. Thus it may make sens to load large binary data objects from external sources, rather than including them.

JAR file optimisation/obfuscation can be beneficial for code footprint because it may
remove unused code,
rename methods and classes, such that they use less space in the symbol table,
make \verb|static const|s work as \verb|#define|s,
 and optimise the code, thus shortening it.
This also allows one to make more readable code with less concern for the code footprint, knowing that some of the more verbose parts will be optimised away.

Using the unnamed package saves space in the symbol table, as class references becomes shorter.

The code footprint limit may be tighter that the run time memory limit, and it may be possible to partition the execution such that different parts of the application do not need to use run time memory at the same time.
Thus, in this project with the design of an embedded scripting language, code footprint will be prioritised slightly higher than the run time memory usage, although both are important.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Programming Languages}
The following sections surveys different programming languages:
\begin{itemize}
\item Forth is surveyed as this language runs on very minimalistic systems, and is also a stack language, thus relevant for the design of virtual machines. 
\item Hecl is the major scripting language for mobile devices, which should therefor be investigated for this project.
\item JavaScript is the basis for LightScript implemented in this thesis
\item Lua has a focus on embedded devices, and solutions from their implementation can inspire the languages created here. There is also an implementation of the Lua virtual machine, targeting mobile devices, why this language is also related to the benchmarks later on.
\item Python is becoming relevant on mobile devices, as it runs on many smart phones. Some of the language features may be usable in the design of new languages.
\item Lisp and Scheme are some of the inspirations for Yolan, especially with regard to the syntax. 
\item Self is highly relevant for the LightScript implementation, as the object system is based on this, via JavaScript.
\end{itemize}


\subsection{Forth and other stack languages}
\index{Forth}
Forth is a stack-based language.
It is very interesting for this project, as it is an example of an interpreted minimalistic language running on even very low-end devices.

The syntax of Forth is different from that of most modern languages, due to the use of reverse polish notation.
Functions work on a stack, which the programmer is explicitly aware of. 
Functions or `words', replace the parameters on the top of the stack with the result. 
New words/functions can be defined, and are concatenative in the sense that functions written after each other have the same semantics as function body themselves written after each other.
Beside the stack for parameters, there is also a stack for return addresses.

%Forth looks very strange when starting looking at the programs, but it seems like it is the question of getting habit of being aware of the stack.
The programming style is focused on decompositions. Forth supports meta programming.
Forth systems have explicit compilation, the system has two modes: compile mode and interpret mode. 
It is possible to create words that are executed at compile time, using the immediate keyword.
Words -- ``functions'' in Forth -- are first class data types.

A couple of very pointers related to Forth are: 
``Thinking Forth'' is a very good book, not only on Forth programming, but also touches a lot programming and problem solving in general. This include details on implementation of stack-based languages.
There is also a tutorial Forth implementation \cite{jonesforth}, that shows how Forth, and thereby stack machines, can be implemented - it is the implementation of a full Forth system, written in assembler, but very readable and well documented.

\index{Virtual machine}
Forth is also interesting from the virtual machine point of view, as it similar to the languages of a stack-based virtual machines. So Forth implementation techniques share a lot those of virtual machines. And research within this topic overlaps, an example is a dissertation on implementation of stack languages on register-based machine \cite{ertl-dissertation}, which uses Forth as the representitive stack-based language.

Other more recent stack languages are Joy \cite{joy-language}, Cat \cite{cat-language} and Factor \cite{factor-language}.
Interesting developments here are stronger typing, and also the use of anonymous code blocks to create the control structure.
The idea of the anonymous code block is an inspiration for the Yolan scripting language developed in this thesis, as the concept of delayed computation is somewhat similar.


\subsection{Hecl and Tcl}
\index{Hecl}
\index{Tcl}
Hecl appears to be the major mobile scripting language, and is a dialect of Tcl. 
Tcl (Tool Command Language) is an embeddable scripting language \cite{tclbook} with a prefix notation, e.g. the syntax is similar to Logo, -- and also similar to Lisp if we see each unquoted line break as an end+begin parenthesis \verb|)(|. Unquoted here means not within quotations or brackets which is also a kind of quoting in Tcl.
In order to avoid prefix mathematical expressions, Tcl has the notion of expressions, which can be evaluated with the \verb|expr| command or as the condition in \verb|if|-statments etc, for example:
\begin{verbatim}
expr (1 + 2) * 3 + 4 * 5
\end{verbatim}
yields 29. Hecl does not have this notions of expressions, meaning that the above calculation would have to be written as:
\begin{verbatim}
+ [* [+ 1 2] 3] [* 4 5]
\end{verbatim}

A very interesting feature of Tcl and Hecl is the \verb|upeval| which allows introduction of new syntax by evaluating an expression one level earlier on the stack. 
This is possible as conditions and code blocks are usually quoted, for example the tcl code:
\begin{verbatim}
if { 1 < 2 } {
    puts Foo
} else {
    puts Bar
}
\end{verbatim}
would be similar to Lisp-notation \verb|(if '(1 < 2) '(puts 'Foo) 'else '(puts 'Bar))|, where it is the responsibility of \verb|if| to evaluate the condition as an expression and then evaluate the correct block. 

Another aspect of Tcl is that everything are string, meaning that for example variable names are just strings, and if we want to read the value of a variable, we have to explicit tell that it should be looked up, by prepending it with \verb|$|.

\subsection{JavaScript/EcmaScript}
\label{JavaScript}
\index{EcmaScript}
JavaScript was created as scripting language for web browsers, and was later standardised under the name of EcmaScript \cite{ecma-262}.
The reason it has become interesting is that it is included within most webbrowsers, and there by one of the most widely available platforms.

It is a dynamically typed scripting language with closures / first class functions, and a prototypical object system.
While it has expressive language features, it is also a very mainstream languages, both through its presence within the web and C-like syntax, and thus it may be less intimidating for new programmers.
\index{Closure}

When making a new scripting language for mobile devices, it may make sense to make it a subset of EcmaScript for several reasons: It already exist as a platform meaning that the new scripting language already has virtual machines deployed. As the EcmaScript syntax is known, or at least recognisable for many developers, even web-``developers'' and users, it may be easier for them to transition, or start using the new scripting language on mobile devices. While being a subset of EcmaScript, closures and higher order functions can still be a part of the language.

An issue with EcmaScript is that it has some unfortunate design decisions\cite{crockford-web}, which will be elaborated on in section~\ref{lightscript-design}.


The following sections looks at the implementation of EcmaScript, and existing approache to EcmaScript on mobile devices. Implementation techniques from those, as well as existing work, may be relevant as one of the scripting languages developed in this thesis is a subset of EcmaScript.
%At the same time, the language was developed in a hurry, also leading to some less fortunate design choices
%A good introduction to JavaScript is given in the book ``JavaScript the good parts'' \cite{goodparts} and some of its material is also available online which serves well as an overview of the language. The EcmaScript standard \cite{ecma-262} can be used for getting to know the details of the languages.

\subsubsection{Implementations}
The following section described the main open source implementations of JavaScript/EcmaScript.

\paragraph{JavaScriptCore} 
\index{JavaScriptCore}
JavaScriptCore is the implementation of JavaScript in Webkit.
The latest version has is called SquirrelFish and is an optimised register-based virtual machine,
with emerging support for JIT compilation.

\index{SquirrelFish}
The engine has been optimised a lot recently: the earlier versions was evaluating by walking through the abstract syntax tree, and was at that that time similar in performance to SpiderMonkey.
The new version -- SquirrelFish -- is much faster, which means that it is similar in performance to TraceMonkey and V8.

\paragraph{QScript}
\index{QScript}
QScript is the EcmaScript implementation which is a part of QT. This implementation is targeting application scripting rather that web scripting. An interesting part of QScript is its support for automatic binding generation. As WebKit is being integrated with QT, QScript is likely to be replaced with or merged a WebKit scripting engine in the long run.

\paragraph{Rhino}
\index{Rhino}
Rhino is an implementation of JavaScript on top of Java. This is mainly as an embedded language for java applications. The implementation transforms the JavaScript program to Java classes, which is then executed.

\paragraph{SpiderMonkey}
\label{spidermonkey}
\index{SpiderMonkey}
SpiderMonkey \cite{spidermonkey} is the JavaScript engine in Mozillas browsers, and it is also usable as an embeddable engine in other applications. The execution is based on a switch dispatched virtual machine. %TODO:verify-that-I-remember-correctly-here.

\paragraph{TraceMonkey} 
TraceMonkey is a branch of SpideMonkey, which incoperates JIT compilation, with a JIT compiler based on trace trees \cite{trace-tree}, 
\index{TraceMonkey}
which rather than JIT compiling the entire program,
traces and then compiles the most executed paths through the program.
This means that the JIT compiled code gets optimised to the actual execution,
and the approach also reduces the amount of code needed to be compiled.

\paragraph{V8} V8 \cite{v8} is a JavaScript implementation made by Google, and released in 2008 in conjunction with the release of their browser ``Chrome''. 
\index{v8}
While it is not directly connected with the Android platform, a JIT compiler is already in place targeting the ARM CPU, so it seems likely that it will also target mobile devices in the long term.

A main focus and benefit of V8 is high execution speed.
The design builds upon experience from Self/Smalltalk implementations \cite{articles-before-v8}.
It is designed for JIT compilation from the beginning, and it also does some class inference to optimise methods and property accesses.
The idea here is that whenever a property is added to a JavaScript object this create an implicit class. When code is JIT'ed, a property access is compiled to a type check followed by fast code for accessesing the property, similar to that of more static, class based languages. This is possible due to the type check and implicit class, and it is much faster than a traditional JavaScript object property lookup.

The garbage collector is fast, - it is a generational garbage collector with two generations. The young generation is collected with a copy-collector which is linear in the time of live data, and thus heap allocation of activation records is almost free. 
This is combined with a mark and sweep collector when a full collect is needed.

\subsubsection{Targeting mobile devices}

There is the standardised EcmaScript Mobile Profile, which removes some features from the language, but is not implementable in practice on top of CLDC 1.0 as it still relies on floating point numbers

During the project it has turned out that there are other projects working on JavaScript languages for mobile devices.

\index{EcmaScript!Mojax}
Mojax (Mobile Ajax) \cite{mojax} is a properitary virtual machine for an EcmaScript like language. This language is also a subset of of EcmaScript, integer only, and appears not to support exception exceptions nor regular expressions.
The Mojax implementation seems to be a virtual machine which cannot execute scripts directly, but they need to be compiled before they can be loaded.

\index{EcmaScript!Mbedthis}
Mbedthis has a closed source implementation of a subset of JavaScript, this one targeting embedded devices \cite{mbedthis}. This uses integers by default, and does not have exceptions, labelled statements, switch, while, do-while, regular expressions, function literals, object literals, array literals, prototypes nor class methods.
% http://www.embedthis.com/products/appweb/doc/guide/appweb/users/ejs/overview.html
Recently that implementation seems to have been abandoned, in favor of new, more compliant implementation: Ejscript \cite{ejscript}.
%http://www.ejscript.org/products/ejs/index.html
While the C based implementation is available under GPL, there apparently is a J2ME implemention which is not published yet.
\index{EcmaScript!Ejscript}

\subsection{Lua}
\index{Lua}
Lua is interesting, both as a language design/implementation, as it have looked into issues that also comes up in this project, and also as a language for low end devices, as lua implementations are available on embedded and mobile devices.
Lua is a dynamically typed, statically scoped embeddable scripting language, which is characterized by only have one datastructure: associative tables.
It has both good performance, and relatively low code footprint, and is as such also interesting for this project.

On mobile devices there is an implementation of the Lua virtual machine called Kahlua \cite{kahlua}.
This is only the Lua virtual machine.

\subsection{Python}
As phones are becoming more powerful, Python is beginning to play a role as a mobile scripting language on high end devices. This is carrying over from being a popular and major scripting language on computer platforms.

Python have some nice features, that may be inspiring when implementing other languages. Comments/documentation is integrated in the language via the concept of docstrings, which is a special kind of comment that will also be available for inspection during runtime. Unit testing is also integrated within the documentation framework, where a special syntax indicates that code in the documentation can also be executed when running tests.
Required indentation leads to easier readable programs.

The issue with Python on mobile devices is, that it is relatively resource intensive, and thus use more energy, and is only available on high end phones.

\subsection{Scheme and Lisp}
\index{Lisp and Scheme}
Scheme and Lisp are especially interesting in this context, due to their minimalism, which inspiring in the design of a language with strong restrictions on the implementation environment.
The syntax is mostly isomorphic with the abstract syntax tree, meaning that parsing is mostly trivial.

For mobile devices, early versions of JScheme \cite{norvig-jscheme} are small enough, that they can be made to run, even with the limitations of footprint on the low end devices. It would need to be ported, as it uses parts of the language not available on the limited devices, but it can be usable as a benchmark tartget due to the sensible footprint size.

Another Scheme implementation, which targets mobile devices is ULM (Un Langage pour la Mobilité) which is a part of a thesis on agent systems \cite{ulm}. Essentially the implementation is a virtual machine, which runs as a backend of a modified version of the Bigloo \cite{bigloo} Scheme compiler.
This was considered as a potential benchmark target, but I did not have time to get it to run, due to issues with dependencies, and at the same time it has a relatively large code footprint -- 96KB.

\subsection{Self}
\index{Self}
\index{Prototypical inheritance}
\label{survey-self}
Self \cite{self} is especially interesting due to its use of prototypical inheritance.
In traditional object oriented programming, we have classes and objects, where classes can inherit from other classes, and objects are instantiations of classes.
Instead of classes and subclasses for inheritance, Self has a clone operator, which creates a new object using an existing object as blueprint.
An object in Self contains a pointer to the parent (cloned) object, and a mapping from property names to values or methods. When a property is read, the mapping of the current object is first searched, and if the name is not found there, then the parent objects are searched for the property.

\section{Interpreter implementation}
\label{interpreter-implementation}

As we are building on top of Java, 
several interpreter implementation issues
becomes less relevant:
\begin{itemize}
\item On this platform, the dispatch can only be implemented 
with a switch statement, or based on class types, where the
latter is much more expensive, spacewise, and therefore not applicable.
Threaded dispatch, and other faster dispatch methods is not possible
due to restrictions of the JVM.
\item With regard to garbage collection, we can piggyback on the garbage collector from the JVM, which saves code footprint as we do not need to implement one ourselves. This has the issue that we can not rely on how it is implemented, meaning that heap allocated activation records may be less of an option, as it is stongly affected by the performance of the garbage collector.
\item JIT compilation to native code, or targeting the JVM, is not possible as dynamic loading of code is not supported at all on most Java Micro Edition implementations.
\end{itemize}

The next section looks at register vs. stack virtual machines, which is an important aspect at the design of virtual machines. This is followed by a look at parsing, more specificly the top down operator precedence parser as this has low code footprint, which is important on this platform. And finally there is an investigation of scope and implementation of variables.

%as the embedded-C implementation of the language was not finished, this part does not belong in the thesis, but should be removed, and possibly make it into later documents. Keep note about using switch due to JVM, which is suboptimal compared to what can be done on a native machine.
%... jvm only switch based or class based, which is suboptimal

%as the embedded-C implementation of the language was not finished, this part does not belong in the thesis, but should be removed, and possibly make it into later documents. Replace note about piggy-backing on the JVM GC, which is unlikely to be generational, which means that heap allocated stack will be expensive.
%... heap allocated stack frames and generational GC.
%The KVM, which is the reference implementation for mobile Java Virtual Machines, is now using a compacting mark and sweep. It originally started out with a copying collector, which had a larger memory requirement. And subsequently it used a non-compacting mark and sweep, where compaction were later added.


%This section looks into different aspects of interpreter implementation.
%First, is a discussion on different types of virtual machines, namely register and stack machines, and their different benefits and tradeoffs. 
%Then, there is a discussion on the implementation of dispatch, which is one of the bottlenecks of intepreters.
%Third, there is a discussion of garbage collection techniques.
%And finally there is a discussion on different approaches to managing run time stack.

\subsection{Register and stack machines}
Virtual machines are usually either register-based or stack-based.

Stack-based virtual machines operates similar to the language Forth, where the operations work on the top of the stack. 
Operands are implicit coded, such that for example the add instruction just pops the two top elements of the stack, and pushes the sum. 
Stack machines are easy to compile to, 
which can simply be done by emitting the opcodes of a post-order walk through of the abstract syntax tree. 
There are no issues of register allocation, spilling, etc.
Stack machines are commonly used, the best known example being the Java Virtual Machine, and there many others that turn out to be stack machines when looking under the hood, for example: Python, the SpiderMonkey JavaScript implementation, and the .NET Common Intermediate Language.

Register-based virtual machines are becoming more common. 
Usually they have a high number of registers, leading to longer opcodes than stack-based virtual machines. But on the other hand, they have fewer opcodes, leading to faster execution \cite{register-vs-stack1, register-vs-stack2}. 
Examples of register-based virtual machines are the Dalvik \cite{dalvik-vm} virtual machine, LLVM \cite{llvm}, Parrot \cite{parrot}, and the virtual machine of Lua 5.0 \cite{luavm}.

A third approach to virtual machines is just to use the abstract syntax tree for evaluation. This was for example used in earlier versions of WebKits JavaScript implementation, but has now been superseded by a stack-based virtual machine, and is currently being replaced by JIT compilation.

\subsection{Parsing}
A language implementation must parse the source text into the abstract syntax tree that is manipulated by the rest of the compiler.

An issue here is that parsers often take quite a large amount of code, especially if they are generated by compiler-compilers.
Generated lexers and LALR(1) parsers, generated by for example \cite{yacc, yacc2}, usually have quite large state tables.
Recursive descent parsers seems to use a bit less code footprint that LALR parsers, but still requires functions for the all the grammar productions, which may still be expensive.
Grammar based parser generation and implementation has been extensively studied and described for example in  \cite{basics-of-compiler-design, grammar}, and will not be discussed further in these sections.

Another approach, which is also very elegant, 
but have recieved less attention is the
top down operator precedences parser.
This has the benefit of a low code footprint,
partly due to genericity of the parser code,
for example: only one parsing
function is needed for the left associative infix operators,
one function is needed for the right associative infix operators,
one function is needed for prefix operators, et cetera.
So a top down operator precedence parser will be used for the implementation of LightScript.


\subsubsection{Top down operator precedence parsers}
\label{tdop}
Top down operator precedence parsing combines recursive descent parsing with operator precedence, which simplifies the implementation significantly.
It was first described thirty years ago \cite{top-down-operator-precedence}, but has not received much attention until lately \cite{beautiful-code, crockford-tdop}.

A token can have a null denominator function, a left denominator function and a precedence.
The null denominator function is used to build the abstract syntax tree node, if the token stands first (is leftmost) in an expression.
The left denominator function is used to build the abstract syntax tree node, if we already have something to the left of the token within the expression.
The precedence of the next token is used to determine whether we are done parsing an expression or need to use the that token to build another abstract syntax tree node, by calling left denominator function of the token.

To be able to build the abstract syntax tree node, the left denominator function gets the parsed node to the left of the token as a parameter. Additionally it is possible for the denominator functions to parse expressions to the right of the token by calling the parsing function recursively. Here it is necessary that the parsing function also take a priority as a parameter. This priority parameter ensure that the left denominator functions are not called for tokens with lower priority.

The parsing itself is then simply done, by first calling null denominator function of the first token, and then calling the left denominator functions of the next tokens, as long as the next token has higher priority than the priority passed to the parsing function.
The denominator functions attached to each token are then responsible for building the syntax tree.
So the core loop of the parser is implemented as follows:
\begin{verbatim}
define parse(int priority):
    syntax_tree = next_token.null_denominator()
    while next_token.priority > priority:
        syntax_tree = next_token.left_denominator(syntax_tree)
    return syntax_tree
\end{verbatim}

Now we need to assign meaningful precedence and denominator functions to the tokens:
Atoms, variable names, literals etc., have a null denominator functions that return their node. Unary operations such as minus, not, etc., have a null denominator that calls parse once, and creates a node that applies the operator to the parsed node.
Binary (infix) operators have a left denominator function that creates a node with its parameter as the left hand side and calls parse to construct the right hand side. Binary operators can be made right associative by reducing the priority passed to parse.
The parsing of lists calls parse until the end of the list is reached. Other constructions can be implemented similarly. 

The limitation of this parser as described here is that only one left-hand side expression is passed to the left denominator function, making reverse polish notation languages difficult to implement. A non-recursive version with an explicit stack instead could solve that.

\subsection{Scope}
\index{Scope}
Defining the scope of variable declarations  is important when designing a programming language.
There are two major kind of scopes: static scoping and dynamic scoping.
Static scoping is also called lexical scoping, and corresponds to the lexical structure of the source code.
This is in contrast to dynamic scoping, where variables are accessible other places than in the blocks where they are defined. 
The difference between dynamic and static scoping is exemplified by the following:
\begin{verbatim}
function f() {
    x := 17
}
function g(x) {
    f()
    print(x)
}
g(42)
\end{verbatim}
which would print 42 if it were written in a statically scoped language, and would print 17 if it were written in a dynamically scoped language.

Static scoping is more natural as the scope matches the structure of the code. Dynamic scoping requires more discipline, as it allows the programmer to tamper with local variables of other parts of the code, and counters good habits of information hiding. A very importeant feature is also that static scoping can be used to create closures for functions, which gives extra flexibility to the language.
\index{Closure}
On the other hand, dynamic scoping very trivial to implement, and can thus use slightly less space in the code footprint. 
Dynamic scoping also does not suffer from the problem discussed in Section~\ref{funarg}.
For more advanced language implementations static scoping has the benefit over dynamic scoping, that code is easier to analyse and optimise due to locality, in the sense that the use of variables is limited to the local lexical scope, and thus the optimisations on this part of the code need be concerned with other parts of the code.

\subsubsection{Stacks and activation records}
A typical way to implement local variables is by using a stack.
In this section, we assume we are on a full stack machine; 
in practical implementations on CPUs, the top of the stack is usually implemented in a number of registers instead.

Whenever a function is called, the arguments are pushed onto the stack. Then, when the function is entered, a return pointer is often pushed to the same stack, and space is allocated for the local variables. The computation is then done, and the function returns, jumping back to the call site and restoring the stack size to the original.
The allocation on the stack allows for local variables, and functions can also be recursive without a problem. The space on the stack with the local variables, etc., is called the activation record for the function.

\subsubsection{Scope and first class functions}

When we have first class functions and static scoping, we cannot just place the activation records on the stack. Inner functions may live on, and access local variables of the outer function, after the outer function has returned. Consider the following code:
\begin{verbatim}
function f(x) {
    function g(y) {
        return x + y
    }
    return g
}
\end{verbatim}

In this code the new function $g$ lives on after $f$ has returned, and at the same time $g$ uses a value that lies in the activation record of $f$. Therefore, if the activation record is allocated on the call stack, and nothing further is done about it, the value of $x$ will no longer be available at the time $g$ is called.
This is an example of the funarg problem, which is the problem with scoping when a function is given as an argument or returned.
\label{funarg}

There are several solutions to this problem:
\begin{itemize}
\item Disallowing/not supporting first-order nested functions or access to outer scope within nested functions. Or not having static scope.
\item Outer scope variables cannot be changed from the inner scope, but are instead passed as immutable values at function/scope creation. 
\item Allocate the activation records on the heap, instead of the stack, and let them be garbage collected. 
\item Keep track of which variables may live on after the function exits, and move those to the heap.
\end{itemize}

Not having nested functions, only having a single-function-local and a global scope, or not having static scope, simplifies the implementation and is a solution in mostly imperative languages.
This solves the issue, but at the same time it also removes support for closures.
\index{Closure}

Copying outer scope variables to inner scope is possible in functional languages, where they are will not be mutated. If the language is not purely functional, the issue with this approach is that when a variable is mutated in an inner function, it is only the copy that is mutated, and the mutation is local to the function.
A workaround for mutations in languages that copy variables from outer to inner scope is to use a reference to the mutated variable rather than the variable itself, such that when the reference is copied to the inner scope it is still possible to mutate the value, as we need not mutate the reference itself.

Another approach is to let the outer scope stay alive until the inner closure dies, and then just reference variables as usual.
This can be done by allocating the activation records on a garbage-collected heap,
which is not as expensive as it may seem, due to the high effiency of modern garbage collectors.
Another approach is to keep track of which variables may stay alive at the exit of a function, and move them to the heap at that time.
Or just identify variables that are used by in inner functions, and put those on the heap.

\subsubsection{Implementation of variables}
When we are implementing the scope, an issue is how to implement the variables. 
Here are several options: 

The  classical good-performing approach is to implement them on a stack. On each function call, an activation record is added on a linear stack, and each of the variables can be spilled into its place on the activation record. This is very fast, as allocation and deallocation just increase and decrease the stack pointer. The issue with this approach is that extra code is needed to handle the funarg problem.

Another approach is to allocate the stack frame on the heap, and let it be cleaned up with the garbage collector. The quality of this approach depends a lot on the garbage collector. In particular it has nearly no overhead with a good generational garbage collector \cite{generational-heap}.
This also solves the funarg problem as the closure has a reference to the activation record, which will then not be garbage collected.

Usually the variable is resolved at compilation time, or the first time it is encountered, but 
some interpreters have a less efficient approach, where they look up variables at run time, either through a stack, or a table of variables.

\chapter{Yolan}
\label{yolan}
\index{Yolan}
\section{Design choices}
The overall design direction of Yolan is to minimise the code footprint, while still having a scripting language with first class functions.
The next paragraphs elaborate the following design choices:
\begin{itemize}
\item Should be able to run on CLDC 1.0
\item Use standard Java classes, for easier interaction with Java code
\item Execution of code, loaded as source text at run time
\item Functions as first class values
\item Efficient variable access
\item Integer only, - no support for floating point number
\item Null is false
\item Lisp like syntax
\item Dynamic scope
\item Builtin support for arrays, hashtables, etc.
\item Lazy Java interface
\item Online exection
\item Only single threaded/non-reentrant to archive small size
\end{itemize}

CLDC 1.0 is the most limited device configurations and API for mobile devices. If the language is able to run this configuration, it will also be able to run on the other Java configurations, and thus be able to run on most devices.

\label{yolandesign}
Use of standard Java classes instead of custom classes for builtin data types such as arrays or tables has three benefits: the code footprint is smaller, as these data types do not have to be implemented, it may be faster, as the builtins may be implented natively, and it is easier embeddable, as as the developers already know the data types from standard Java.
The issue of using the builtins is that it gives less flexibility to the design of the behaviour of the data types in Yolan.

Being able to load code at run time is important for several reasons:
It allows larger programs, than would otherwise be possible within the devices, as the different parts of the program can be loaded and unloaded as needed.
It allows adding updates and new features to the programs, without needing them to be reinstalled manually.
It allows the language to be used for configuration files, and data initialisation.
Being loaded as source code both gives more clarity, and makes it easier to distribute and edit, thus making it more suitable for for use as configuration language, and scripting by users.

Functions should be first class values, both to enable functional programming and increase the expressiveness of the language.

If variables are looked up at every access at runtime, this is likely to be bottleneck for performance, and instead the implementation must ensure that they are only resolved once for each place they are used in the source text.
The platform is already slow, so performance wise we probably can not afford not doing this optimisation.

Integers is the only number type supported on the platform. Floating point numbers would have to be emulated, which would both give a performance penalty, and more importantly a huge increase in code footprint due to emulation code.

Null is also the false value. This simplifies the implementation slightly, and thus reduces the footprint.

Yolan has a Lisp-inspired syntax. This trivialises the parser ipmlementation, and thus reduces code footprint.

Dynamic scope removes the issue of the funarg problem, and thus simplifies the implementation of variables. This is generally bad language design, but at the same time it may reduce the code footprint slightly.
\index{Scope}

The language is more like a traditional scripting language, than a functional language, 
as it does not support tail recursion nor has cons-list, but instead it uses resizable arrays and hashtable as data structures, and has more imperative programming model, with while- and foreach-loops, etc.
The motivation for this is that it is simpler to implement efficiently on top of an already imperative/objectoriented virtual machine, and that functional languages often are less space efficient.

If the interface with Java is lazy, this allows new control flow constructs to be added, by the embedded, which again allows the implementation to be a small core, with support for expansion.

Execution should be online, in the sense that whenever a full statement is read from the input, it should be executed, not needing to read the full file. This is both practical for interactive evaluation, and also has a benefit memorywise as the entire program never needs to be fully in memory, as executed code may be garbage collected.

By only having a single runtime, some classes can be made static and merged, leading to a smaller code footprint. This is a tradeoff leading to non-reentrant code and no support for threads.

\section{Syntax tree rewriting}

To make the interpreter as simple as possible, it interprets the syntax tree directly. Still this has some performance issues, as, for example variable and function lookup would be done at each execution. To avoid the cost of this some of the evaluation functions instead resolves the variables the first time they are executed and replaces the node itself with a node of the resolved variable or function.

\section{Language specification}

\subsection{Syntax}
\subsubsection{Function application / lists}
Function applications are written in Lisp-style as lists. The first element in the list is the function to be applied.
Lists are enclosed within square brackets \verb|[|$\cdots$\verb|]|, and may be nested. 
The reason to use square brackets, rarther than parenthesis as in Lisp, is that that the lists is not cons-list, but instead arrays, which are usually written with square bracket notation in other scripting languages. This is also an indication that Yolan is not a proper Lisp like functional language, but rather an scripting language. The notation is also similar to Tcl, except that there are not automatic expression breaks at new lines.
The elements within the lists are separated by whitespace. 
As lists are the notation for function applications, every list must have at least one element, which is an expression evaluating to the function to be applied.

\subsubsection{Variable names}
A variable name is a sequence of characters. The possible characters are letters, numbers, the symbols \verb"!#$'()*+-,-./:<=>?@\^_`{|}~", and any unicode symbol with an unicode value of 127 or higher. The first character in the name of a variable must be non-numeric.

\subsubsection{Integer literals}

Integers are written as a sequence of digits (\verb|0123456789|). Only base 10 input is possible and only non-negative numbers can be written as literals. Negative integers must be generated by subtraction.

\subsubsection{Comments and whitespaces}
Characters with a unicode value of 32 or less are regarded as whitespaces. This includes the usual space, tab, newline, and line-feed. Whitespace is used to separate list elements, and is discarded during parsing. A comment must be preceded by whitespace, starts with a semicolon \verb|;| and continues until the end of the line. Comments are discarded during parsing.

\subsection{Builtin functions}
The builtin functions are listed below. As the language is designed for embedding in other applications, there are no standard functions for input/output, file access, network, etc. as these might not be present or differ significantly between target devices/platforms.

In the following, function names are written with {\tt fixed width} font, and the arguments are written in $cursive$. Arguments can be any expression, and are named according to their type or functionality: $num$s are expressions that should evaluate to numbers, $exp$s are expressions that may be optionally evaluated (e.g. in {\tt if}), $val$s are expressions will be evaluated, $string$s are expressions that should evaluate to a string, and so on.

\subsubsection{Variables}
\subsubsection*{\tt{[set }$name$ $value$\tt{]}}
Evaluate the expression $value$ and let the variable $name$ refer to the result.

\subsubsection*{\tt{[locals [}$name_1 \cdots name_n$\tt{]} $expr_1 \cdots expr_n$\tt{]}}
Let $name_1 \cdots name_n$ be local variables in $expr_1 \cdots expr_n$: First save the values corresponding to $name_1 \cdots name_n$, then evaluate the expressions $expr_1 \cdots expr_n$, next restore the values of $name_1 \cdots name_n$ and finally return the result of the evaluation of $expr_n$. The expressions are evaluated in order, with $expr_1$ as the first one, and $expr_n$ as the last one.

\subsubsection{Conditionals and logic}
\subsubsection*{\tt{[if }$cond$ $expr_1$ $expr_2$\tt{]}}
Evaluate $cond$ and if the result is non-$nil$ then evaluate and return $expr_1$, else evaluate and return $expr_2$.

\subsubsection*{\tt{[not }$cond$\tt{]}}
If the value of $cond$ is $nil$ return $true$ else return $nil$.

\subsubsection*{\tt{[and }$expr_1$ $expr_2$\tt{]}}
Evaluate $expr_1$ and if it is non-$nil$, evaluate and return the value of $expr_2$, else return $nil$.

\subsubsection*{\tt{[or }$expr_1$ $expr_2$\tt{]}}
Evaluate $expr_1$ and if it is non-$nil$ return its value, else evaluate and return the value of $expr_2$.

\subsubsection{Repetition and sequencing}
\subsubsection*{\tt{[repeat }$num$ $expr_1 \cdots expr_n$\tt{]}}
Evaluate $expr_1 \cdots expr_n$ $num$ number of times ($num$ is evaluated once, and must evaluate to a number). The result is the last execution of $expr_n$, or $nil$ if no expressions were evaluated, i.e. $num \leq 0$.

\subsubsection*{\tt{[foreach }$name$ $iterator$ $expr_1 \cdots expr_n$\tt{]}}
For every value from the $iterator$, bind it to the local $name$ and evaluate $expr_1 \cdots expr_n$. The result of the evaluation is the last executed $expr_n$ or $nil$ if no expressions were evaluated. $name$ is a local variable, and is thus saved before the loop, and restored afterwards.

\subsubsection*{\tt{[while }$cond$ $expr_1 \cdots expr_n$\tt{]}}
While $cond$ evaluates to non-$nil$, evaluate $expr_1 \cdots expr_n$, and return the value of the last $expr_n$ or $nil$ if no expressions were evaluated.


\subsubsection*{\tt{[do }$expr_1 \cdots expr_n$\tt{]}}
Evaluate $expr_1 \cdots expr_n$ and return the result of $expr_n$.


\subsubsection{Functions}
\subsubsection*{\tt{[lambda [}$name_1 \cdots name_n$\tt{]} $expr_1 \cdots expr_n$\tt{]}}
Create a new anonymous function, with the parameters $name_1\cdots name_n$. Application of the function will bind its arguments to local variables $name_1\cdots name_n$, evaluate $expr_1\cdots expr_n$ and return $expr_n$, saving and restoring $name_1\cdots name_n$ when entering and exiting the function.

\subsubsection*{\tt{[defun [}$name_{function}$ $name_1 \cdots name_n$\tt{]} $expr_1 \cdots expr_n$\tt{]}}
Create a new function, and bind it to the variable $name_{function}$. The \verb|defun| statement above is equivalent to {\tt{[set }}$name_{function}${\tt{ [lambda [}}$name_1 \cdots name_n${\tt{]}} $expr_1 \cdots expr_n${\tt{]]}}.

\subsubsection*{\tt{[apply }$function$ $param_1 \cdots param_n$\tt{]}}
Apply the $function$ to the parameters $param_1\cdots param_n$. The difference between this and the usual function application {\tt{[}$function$ $param_1\cdots param_n$\tt{]}} is that that \verb|apply| allows $function$ to change between invocations, whereas the usual function application assumes that $function$ is static, to be able to optimise it during runtime.

\subsubsection{Integer operations}
\subsubsection*{\tt{[+ }$num_1$ $num_2$\tt{]}}
Calculate the sum of two integers.
\subsubsection*{\tt{[- }$num_1$ $num_2$\tt{]}}
Calculate the difference of two integers, the result is $num_2$ subtracted from $num_1$.
\subsubsection*{\tt{[* }$num_1$ $num_2$\tt{]}}
Calculate the product of two integers.
\subsubsection*{\tt{[/ }$num_1$ $num_2$\tt{]}}
Integer division, $num_1$ is divided by $num_2$.
\subsubsection*{\tt{[\% }$num_1$ $num_2$\tt{]}}
Returns the remainder of dividing $num_1$ by $num_2$.

\subsubsection{Type predicates}
\subsubsection*{\tt{[is-integer }$val$\tt{]}}
Returns $true$ if $val$ is an integer.
\subsubsection*{\tt{[is-string }$val$\tt{]}}
Returns $true$ if $val$ is a string.
\subsubsection*{\tt{[is-list }$val$\tt{]}}
Returns $true$ if $val$ is a list.
\subsubsection*{\tt{[is-dictionary }$val$\tt{]}}
Returns $true$ if $val$ is a dictionary.
\subsubsection*{\tt{[is-iterator }$val$\tt{]}}
Returns $true$ if $val$ is a iterator.

\subsubsection{Polymorphic functions}
\subsubsection*{\tt{[equals }$val_1$ $val_2$\tt{]}}
Compare $val_1$ to $val_2$ and return $true$ if they are the same, or $nil$ if they are different. $val_1$ and $val_2$ must have the same type, and should either be integers or strings.
\subsubsection*{\tt{[is-empty }$val$\tt{]}}
Returns $true$ if a list, dictionary or iterator does not have any elements. Otherwise, it returns $nil$.
\subsubsection*{\tt{[put }$container$ $position$ $value$\tt{]}}
Store a value into a list or a dictionary. If the container is a list, the $position$ must be an integer in the range $0,1, \cdots, ${\tt{[size }}$container${\tt{]}}$-1$.
If the container is a dictionary, the position must be a string or an integer. An entry is deleted from a dictionary by storing $nil$ as the $value$.
\subsubsection*{\tt{[get }$container$ $position$\tt{]}}
Retrieve a value from a list or a dictionary. It has the same constraints on $position$ as with \verb|put|. Retrieving an uninitialised entry from a dictionary yields $nil$.
\subsubsection*{\tt{[random }$val$\tt{]}}
If $val$ is an integer, return a random number in the range $0,1, \cdots, val -1$. If $val$ is a list, pick a random value from the list.
\subsubsection*{\tt{[size }$val$\tt{]}}
Return the length of a string, the number of values in a list, or the number of entries in a dictionary.
\subsubsection*{\tt{[< }$val_1$ $val_2$\tt{]}}
Compares $val_1$ with $val_2$. If $val_1$ and $val_2$ are integers, return $true$ if $val_1$ is strictly less than $val_2$ and otherwise $nil$.
If $val_1$ and $val_2$ are strings, do a lexicographical comparison and return $true$ if $val_1$ comes strictly before $val_2$, and otherwise $nil$.
\subsubsection*{\tt{[<= }$val_1$ $val_2$\tt{]}}
Compares $val_1$ with $val_2$. If $val_1$ and $val_2$ are integers, return $true$ if $val_1$ is less than or equal to $val_2$ and otherwise $nil$.
If $val_1$ and $val_2$ are strings, do a lexicographical comparison and return $true$ if they are equal or $val_1$ comes before $val_2$, and otherwise $nil$.

\subsubsection{String functions}
\subsubsection*{\tt{[stringjoin }$val_1\cdots val_n$\tt{]}}
Create a string by concatenating $val_1\cdots val_n$.
If $val_i$ is an integer or a list, it is converted to a string.
A list is converted to a string by concatenating its elements, as if {\tt stringjoin} were called with the list elements as arguments.

\subsubsection*{\tt{[substring }$string$ $num_{begin}$ $num_{end}$\tt{]}}
Create a substring from a string, starting inclusively at character position $num_{begin}$ and ending exclusively at character position $num_{end}$. The positions starts counting at $0$, so thus {\tt{[substring }$string$ $0$ \tt{[size }$string$\tt{]]}} is the entire string.

\subsubsection{List functions}
The following functions works on lists. Notice that lists in Yolan is similar to lists in Python, and thus the functions below are imperative in such that the alters the list parameter, which is different to what happens in functional languages, where lists are typically cons-cells. When speaking about the end of the list, it is the element at the position equal to the length of the list minus one.

\subsubsection*{\tt{[list }$val_1\cdots val_n$\tt{]}}
Create a new list, containing the elements $val_1\cdots val_n$.

\subsubsection*{\tt{[resize }$list$ $num$\tt{]}}
Change the size of the $list$ to be $num$ elements. 
If the new size is larger than the current size, new elements will be added to the end of the list, with the initial value of nil. If the new size is smaller than the current size, then the list will be truncated at the end. The list is modified by the function and then returned.

\subsubsection*{\tt{[push }$list$ $val$\tt{]}}
Push the value $val$ at the end of the $list$. The size of the list grows by one, and the last element is now $val$.

\subsubsection*{\tt{[pop }$list$\tt{]}}
Remove the element at the end list. The function returns that element, and reduces the size of the list by one.

\subsubsection{Dictionary functions}
\subsubsection*{\tt{[dict }$key_1$  $val_1$ $\cdots$ $key_n$ $val_n$\tt{]}}
Create a new dictionary with $n$ entries, where $key_1$ maps to $val_1$ and so forth.

\subsubsection{Iterator functions}
\subsubsection*{\tt{[keys }$dictionary$\tt{]}}
Create a new iterator across the keys of a dictionary.
\subsubsection*{\tt{[values }$container$\tt{]}}
Create a new iterator across the values of either a dictionary or a list.
\subsubsection*{\tt{[get-next }$iterator$\tt{]}}
Get the next element from the iterator, or nil if the iterator is empty.

\section{Developer guide to embedding Yolan in Java}
Yolan is a minimal scripting language implemented on Java.
It allows scripting to be added to an application, with a minimal overhead in the size of the JAR file -- which is the most limiting factor on low end mobile devices. The features and limitations of Yolan are:
\begin{itemize}
\item It is scripting language, with support for higher-order functions
\item Yolan supports loading of code at run time
\item The datatypes of Yolan is implemented with the classes from the Java standard library, such as \verb|java.lang.Integer|, \verb|java.util.Hashtable| and \verb|java.util.Stack|, which makes it easier to interact with Java applications.
\item It is implemented on top of Java Micro Edition/J2ME, and requires only CLDC 1.0.
\item Adding scripting support to an application adds approximately 5KB to the size of the optimised JAR file
\item Expressions are parsed and executed one at a time, allowing interactive programming, and implying that the entire program need not to be in memory at once
\item Yolan scripts are interpreted -- they can be entered directly on the device, not needing an extra step of compilation, and thus it is also suitable for scriptable configuration files, user scripts etc.
\end{itemize}

The implementation of Yolan consists of a single class \verb|Yolan| with the actual implementation, and an interface \verb|Function|, which specifies what a class need to implement in order to be callable from Yolan.
While Yolan only has a single classfile for the implementation, in order to reduce the JAR file size, it consists of several logical classes: a parser implemented as static properties, a runtime implemented as static properties, and delayed computations implemented as objects that can be instantiated.

Having a single runtime reduces memory usage, but also limits applications to only executing a single script, and only having a single execution context at a time. The reduction of memory usage comes from that refererences to the execution context can be hard coded, and thus the delayed computations do not have to carry a reference to the context. There is also a memory reduction because less code is needed and the class for the context can be joined into the main class file, as static properties.
The delayed computation is the same as a node in the abstract syntax tree, as the scope is dynamic and execution context is global. 


The \verb|Function| interface consists of a function that takes an array of Yolan objects -- delayed computations -- as parameter, and the return a value. In this sense Java objects callable from Yolan are essentially lazy functions, and themselves responsible for evaluating their arguments. This makes it easy to add custom control function, similar to \verb|if| and \verb|while|, as it is left up to the called Java function whether, and how many times, each argument expression should be evaluated.

\subsection{Getting Started}
The core method of a Yolan object is the \verb|value()| method which evaluates the code the Yolan object represents, and returns the result. This method may throw \verb|Exeception|s as well as \verb|Error|s if the code it represents has faults, so to make it robust against errors in scripts, the Yolan evaluation must be surrounded by a \verb|catch(Throwable)|.

Yolan objects are created with the static \verb|readExpression| method that parses the next Yolan expression from an input stream. So if we want to create a simple interactive interpreter, reading from the standard input stream \verb|System.in|, we can implement it in Java as: \begin{lstlisting}
class Main {
    public static void main(String [] args) throws java.io.IOException {
        Yolan yl = Yolan.readExpression(System.in);
        while(yl != null) {
            try {
                System.out.println("Result: " + yl.value().toString());
            } catch(Throwable yolanError) {
                System.out.println("Error: " + yolanError.toString());
            }
            yl = Yolan.readExpression(System.in);
        }
    }
}\end{lstlisting} 

This code could be saved in a file called Main.java, placed in a directory with Yolan.class and Function.class, and then compiled and executed by executing \verb|javac Main.java| and \verb|java Main|.

Notice that the input stream \verb|System.in| can be replaced with any input stream, so the same idea can be used for evaluating files, programs as strings within the application, or even as streams across the network, where Yolan could work as a shell for remote scripting/controlling an application.

If we want to execute an entire stream, there is a short hand builtin method for doing that: \verb|eval|. For example:
\begin{lstlisting}
class Main {
    public static void main(String [] args) throws java.io.IOException {
        Yolan.eval(new FileInputStream(new File("script.yl")));
    }
}
\end{lstlisting}
This code opens the file ``script.yl'', and evaluates all the expressions within it. 
\verb|eval| throws away the results of the individual expressions and does not print them,
so the above code is only useful if we have added some userdefined functions to Yolan that allow it to do something practical.

\subsubsection{Adding functions to the runtime}
This section describes how to make Java code callable from Yolan.
While the builtin Yolan functions support basic data structures such as lists and dictionaries,  there is no built in way to do input/output from Yolan that is platform dependent: Java Standard Edition supports files, where Java Micro Edition has a record store, and user interfaces ranges between Midlets, Applets, graphical applications, and text standard-in/out.
\index{Java Micro Edition}
So when a script needs to communicate with the user, or work on the state of the host application, 
some functionality needs to be added. This is most easily done by adding functions to the runtime.

The \verb|Function| interface is the way to do that. To implement the interface a single function \verb|apply| needs to be implemented in the class. 
This function is the actual application of the function within Yolan, and
it takes an array of \verb|Yolan|-objects as argument, and returns the result as a usual Java object.
Notice that the \verb|Yolan|-objects are delayed computations, e.g. they are only evaluated when the called function chooses to evaluate them, by calling their \verb|value()|-function.
Execution of the Yolan object may also have side effects, and thus the number of times \verb|value()| is called per argument matters.
In order to add a new Java function to be callable from the runtime, the method \verb|Yolan.addFunction| takes a string name and a \verb|Function| as parameters, and binds the name to the function. As an example the following code makes a new function, \verb|println|, available to the runtime. This function takes one argument, which it prints out to the standard output:
\begin{lstlisting}
class PrintingFunction implements Function {
    Object apply(Yolan args[]) {
        System.out.println(args[0].value());
    }
}
class Main {
    public static void main(String [] args) throws java.io.IOException {
        Yolan.addFunction("println", new PrintingFunction);
        Yolan.eval(new FileInputStream(new File("script.yl")));
    }
}
\end{lstlisting} 
The above program reads and evaluates the file script.yl, with an augmented runtime that also has the \verb|println| function.

\subsubsection{Code footprint efficient addition of several functions to the runtime}
The naive approach for adding functions to the runtime would be to create a new class implementing the \verb|Function| interface for each function. This would add significantly to the JAR-file
.
If the code size is critical, it can often be reduced by combining multiple functions into a single class, for example via a switch dispatch as shown below:
\begin{lstlisting}
class ManyFunction implements Function {
    int id;
    ManyFunction(int id) {
        this.id = id;
    }
    Object apply(Yolan args[]) {
        switch(id) {
            case 0: // first function
                    ....
                break;
            case 1: // second function
                    ....
                break;
            case 2: // third function
                    ....
                break;
            ....
            default:
                throw SomeKindOfError();
    }
    static void register() {
        Yolan.addFunction(new ManyFunction(0), "firstFunction");
        Yolan.addFunction(new ManyFunction(1), "secondFunction");
        Yolan.addFunction(new ManyFunction(2), "thirdFunction");
        ....
    }
}
\end{lstlisting}

When implementing functions, it is also possible to create control structures, due to the laziness of Yolan objects. This is done by not evaluating the arguments' \verb|value|-functions exactly one time each, but zero or more times, depending on the purpose. The example below shows how the usual if-statement could be implemented:
\begin{lstlisting}
class YolanIf implements Function {
    Object apply(Yolan args[]) {
        // first evaluate the condition
        // and find out if it i true (not null)
        if(arg[0].value() != null) {
            // only evaluate if the condition yields true
            return arg[1].value();
        } else {
            // only evaluate if the condition yield false
            return arg[2].value();
        }
    }
}
\end{lstlisting}
\subsubsection{Values and types}
The builtin types in Yolan are mapped to Java classes for easier interoperability,
so lists are implemented as java.util.Stack, dictionaries are implemented as java.util.Hashtable, strings are implemented as java.lang.String, nil/false is implemented as the value null, integers are implemented as java.lang.Integer, and iterators are implemented as java.util.Enumeration. 
Operations on those data types are just as for the native builtin types. 

Any Java object can be passed around within Yolan, so adding support for new data types is just a question of adding functions that work on those data types.

\subsubsection{Functions defined within Yolan}
When a user defines functions within Yolan, they are instances of the Yolan class. 
Before calling such a function, the number of arguments can be found using the \verb|nargs| method.
If the Yolan object is not a callable user-defined function, the result of \verb|nargs()| is -1, and this is the only API method to check if a Yolan object is a callable function.
The function is then applied with the \verb|apply| method, which takes the arguments to the function as arguments, for example:
\begin{lstlisting}
...
    // evaluation some Yolan object that yields a function
    Yolan function = yl.value();
    // ensure that it is a function and it takes two arguments
    if(function.nargs() == 2) {
        // apply the function 
        result = function.apply(arg1, arg2);
    } else ...
....
\end{lstlisting}
The apply method is defined from zero, up to three arguments. If there is a need for an apply method with more arguments, they are simple to add; see page~\pageref{source-yolan-apply} for the implementation details. There is also a general apply method, that takes an array of arguments as argument.

\subsubsection{Modifying the runtime}

In order for the scripting language to be practical, it should be able to work and share data with the host application. 
Of course this can be done with functions, and evaluation, as described above, but an additional connection with the language can be added by accessing the variables defined, and used, by the running scripts.
For this there are three functions: \verb|Yolan.resolveVar|, \verb|Yolan.getVar|, and \verb|Yolan.setVar|.

When a value is accessed, this is done through a handle, which is found using \verb|resolveVar|. This handle can then be used for reading and writing the variable. The motivation for the handle is that it takes time to lookup what a variable name, so this computation can be done once for each variable that needs to be accessed, and then additional accesses to the resolved variable are significantly faster. The \verb|resolveVar| function takes the variable name as a string parameter, and return the handle, which is an integer. If the variable does not exist in the runtime, space is allocated for it.

With a handle, it is then possible to set the value of a variable with \verb|setVar|. For example setting the variable foo to 42 can be done with:
\begin{lstlisting}
    Yolan.setVar(Yolan.resolveVar("foo"), new Integer(42));
\end{lstlisting} 
and similarly the variable can be read with \verb|getVar|:
\begin{lstlisting}
    Object result = Yolan.getVar(Yolan.resolveVar("foo"));
\end{lstlisting}

If it the variable is commonly accessed, it saves time to cache the handle across calls, as follows:
\begin{lstlisting}
class Class {
    int fooHandle;
    Class() {
        fooHandle = Yolan.resolveVar("foo");
    }

    int someMethod() {
        ... perhaps some scripts modifying foo are executed ...
        Object foo = Yolan.getVar(fooHandle);
        ...
    }

    void otherMethod() {
        ... 
        Yolan.setVar(fooHandle, "A literal value or some variable");
        ...
    }
}
\end{lstlisting}
When defining functions, as described earlier, it is actually the same that is happening: the function is encapsulated in a Yolan object and added to the runtime as done by \verb|setVar|.

\subsubsection{Resetting the runtime and saving space}
When the scripting language is only used in some parts of the application, it can be pratical to be able to unload its runtime data in order to save memory. 
For this there are two utility functions \verb|Yolan.wipe()| and \verb|Yolan.reset()|.

\verb|Yolan.wipe()| sets all references in the runtime to zero, allowing data to be garbage collected.
When the runtime has been wiped, Yolan expressions can no longer be evaluated, and trying to evaluate them will yield errors. 

\verb|Yolan.reset()| resets the runtime: all variable handles are invalidated, all variables are removed from the runtime, and only the builtin functions remain. Existing Yolan expressions are invalid, and evaluation of them may lead to unexpected behavior. User defined functions and variables need to be re-added.
Resetting is necessesary before scripts are executed after a \verb|Yolan.wipe()|.
It can also be practical when multiple scripts are run, one after another, and they must not modify the runtime for each other.

\chapter{LightScript}
\label{lightscript}
\index{LightScript}
\section{Design choices}
The next paragraphs elaborate the following design choices:
\begin{itemize}
\item A subset of EcmaScript.
\item Should be able to run on CLDC 1.0
\item Use standard Java classes, for easier interaction with Java code
\item Execution of code, loaded as source text at run time
\item Functions as first class values
\item Parsing without error checking
\item Integer only, - no support for floating point number.
\item Undefined, null and false, is joined in a single type/value and is the only false value.
\item Support for closures, lexical scope
\item Efficient variable access
\item Objects, and prototypical inheritance with a self-like \verb|clone| function
\item Exceptions
\end{itemize}

There are several reasons to make the language a subset of EcmaScript:
When LightScript is a subset of EcmaScript, it automatically runs within most webbrowsers, including within smartphones where Java may not be installed.
\index{Smartphones}
Being an EcmaScript subset also makes it easier to get started on for developers, that already know EcmaScript, or other languages with C-like syntax.
The issues are that being a subset of EcmaScript will add more complexity to LightScript, and also that EcmaScript has some unfortunate design choices \cite{crockford-web}, e.g. global variables by default, function-scoping rather then block-scoping, non-transitive equality test, traversal of parent object in for-each, arrays and null are objects in typeof-operator, restrictions on names due to many reserved words, automatic semi colon insertion, the with-statement, 
where some of these will also be a part of LightScript,
although many can be omitted by being a subset and thus more strict. 

Like Yolan, LightScript will run on CLDC 1.0, and will use standard classes for better embedding and code footprint size, will support run time loading of source code, and will have functions as first class values. See the Yolan design choices on page~\pageref{yolandesign}.

The parser may assume that the programs have valid syntax. 
Usually parsers both build a syntax tree of valid programs and also reject programs with invalid syntax. 
By removing the rejecting-part, and only require that the can parsers build a syntax tree from valid programs, the parser may be optimised to run better on the limited devices.
The parser should still guarentee to terminate, even with invalid programs though the resulting syntax tree may be undefined.

LightScript only supports integers as number type, due to the platform. This is radically different from EcmaScript, which only supports floating point numbers. Script can still be compatible: addition, and multiplication, subtraction and modulo operations stay within the integer subset of floating point numbers, as long as there are no overflow, and they start out with integers. The shifts and bitwise operators temporarily cast to integer in EcmaScript, so they are not an issue. The only problem of the operators is division, and the solution here is to omit the \verb|/| binary operator from lightScript, and instead allow integer division to be implemented as a function \verb|div|, which can also be implemented in EcmaScript with a combination of division and rounding.

Similar to Yolan, LightScript also only have one false value, which also joins the \verb|undefined|, \verb|null|, and \verb|false| value of EcmaScript, which also removes the boolean type. This is an optimisation that makes truth test faster and slightly smaller, as they can be written as \verb|obj != null|, rather than
\verb%!( obj == null% \verb%|| (obj instanceof% \verb%Boolean% \verb%&&% \verb%!((Boolean)obj).booleanValue() )% \verb%||% \verb%(obj instanceof Integer &&% \verb%((Integer)obj).intvalue()% \verb%== 0 )% \verb%|| (obj instanceof String && obj.equals(""))%. It is still possible to preserve compatibility of scripts with EcmaScripts by requiring that conditions are always boolean values -- as it is required in many static typed languages. Another issue with this choice is, that there are no distinction between \verb|undefined| and \verb|null|, which may desirable.

LightScript should have a lexical scope similar to EcmaScript.
This has the benefit of allowing closures which makes the use of functions much more expressive.
The lexical scope in EcmaScript, and thus LightScript, is a bit different from most other lexical scoping, as the scope limit is the enclosing function rather than the block.
\index{Scope}
\index{Closure}

Similarly to Yolan, LightScript should support fast variable access. This also means that another approach than looking through the chain of execution context objects, as described in the EcmaScript standard must be used. Here LightScript should use a usual execution stack, boxing objects in the closure onto the heap.

LightScript should support an object system similar to EcmaScript.
Inheritance will be slightly different: while EcmaScript has prototypical inheritance, it mixes it with some Java/C++ like syntax. The semantics will be the same for LightScript, but the inheritance will be done with a self-like \verb|clone| clone, which seems more pure prototypical than EcmaScripts syntax. The \verb|clone| function can easily be implemented in EcmaScript.

Exceptions should also be supported, and it should also be possible to throw between, and across Java-functions and LightScript functions.

\section{Imperative implementation of top down operator precedence parsers}
\index{Top down operator precedence parser}
\label{tdop-imp}
This section looks at how top down operator precedence parsers can be implemented efficiently in an imperative language.

As we have relaxed parsing requirements, such that only building the syntax tree, and not checking for error is required, several classes of tokens can be joined. An example is to create an end-of-list token, instead of list termination such as \verb|}|, \verb|)|, \verb|]|, which also allows a generalisation of parsing a list. Similarly a separator token can be introduced instead of \verb|,|, \verb|;|, \verb|:|.

The top down operator precedence parser described in Section~\ref{tdop} 
uses first class functions and are thus better suited for being implemented in functional languages rather than imperative languages.
For example, in Java a simple implementation of the parser uses a lot of space as as the functions would ase a class each, in order to be passed around as first-class values.
Our solution is to use a dispatch function instead, and replace the denominator functions of the token, with integers.
Actually it is simpler with two dispatch functions, one for the null denominator functions and one for the left denominator functions.

The token object contains information about the denominator functions, and corresponding abstract syntax tree node IDs, and also a priority/binding power.
This is just five small integers, which, due to their limited range, easily can be represented within a single 32bit integer. 
Some tokens represents literal values or identifiers, where the value or identifier also has to be passed to the parser.
So a token can be represented compactly as an integer and possibly an object for the value, which eliminates the need for an actual token object in the parse, thereby reducing the footprint by not needing a token class.

The token types can be encoded by the string representing the token followed by the five integers.
The token name string is not needed by the parser, but is used by the tokeniser, to map the token to the IDs.
So the tokens can be written as {\tt "tokenname" + (char) binding\_power + 
(char) null\_deno}\-{\tt{}minator\_function + (char) AST\_ID\_for\_null\_denominator
+ (char) left\_denomina}\-{\tt{}tor}\-{\tt{}\_function + (char) AST\_ID\_for\_left}\-{\tt{}\_denominator}. 
The syntax is implemented as list of the different token types, with the data described above.
For this to be executed there also need to be a parse loop, and definitions of sensible denominator function bodies within the dispatch.
The actual implementation can be seen on page~\pageref{code-lightscript-parser}.


\subsection{Performance properties of the parser implementation}

For each token, there is a instruction cost of 1-2 function calls, 1 switch-dispatch, 0-1 comparisons, extracting of 2-3 parts of the token integer, and storing a copy of the token integer, plus the cost of building the actual AST node, and the cost of the tokenisation itself.

The size of the implementation can be kept very small, as the denominator functions can be reused across different token-types. For example: the binary operators share a single case in the left denominator dispatch, and adding a new binary operator only uses the length in characters of the operator plus 5 bytes. 

\section{Implementation of variables and scope}
\index{Scope}
In the EcmaScript standard, identifier resolution is done by searching through the scope chain, which is a list of objects. Objects in the EcmaScript context are a mapping from property names to values. This approach to implementation would be very performance expensive.

Instead we want to resolve the variables at compile time, while preserving as much of the EcmaScript semantics as is practical. The main issue here is that when we resolve the variable at compile time, we do not keep information to be able to resolve it dynamically at run time,
which lead to limitations in \verb|eval| like statements when compared EcmaScript semantics. Currently there are no \verb|eval| statement in LightScript, but this may be an issue in future versions.

Of the different methods for implementing scope, discussed in Section~\ref{survey-scope}, the only real possibilities for a partly imperative scripting language with support for first-class functions are either to allocate the activation records on the heap, or keep track of variables that could live on after exiting a function, and box those variable on the heap.
The other options are ruled out, as we want to have closures, and we want the outer scope variables to be mutable.
\index{Closure}
As we are implementing on top of the JVM, that also determines the garbage collector, which it may vary on different devices, and which may be badly suited activation record allocation on the heap.
So the approach will be only to box variables onto the heap, that could be alive after function exit.

To simplify this, it is done such that every variable that is added to a closure of an inner function is boxed on the heap, and other local variables are just stack allocated in the usual way. 
%TODO: reference nanopass compiler paper by Kent Dybvig (ICFP in Snowbird) or other papers by dybvig
%I have not seen this exact approach to implement closures other places, but it seems so obvious, that it is probably done somewhere before, although it clearly is different from the Lua approach with upvals \cite{luasrc}, and also from the approach following the EcmaScript standard \cite{ecmascript} directly.

For the practical implementation of the stack on top of the JVM, there are two obvious possibilities: A \verb|java.util.Stack| object could be used, or a stack could be implemented manually with an array and an index pointer. 
In order to select implementation strategy, a microbenchmark was done on the KVM, which indicated that the array approach is significantly faster than the \verb|java.util.Stack|. The array grows dynamically when entering a function that uses more stack space than is available. 
The code footprint size is similar for both approaches, though probably a bit smaller for the Stack, as that one automatically grows, unlike then the array approach, which need a manual implementation.
The actual access to a \verb|Stack| requires a method call, which is 3 bytes plus 1-3 bytes for self and parameter loading, where reading from an array is a single byte opcode plus 2-4 bytes for self, index and parameter loading, and at the same time the array approach sometimes need to adjust the index, costing 3 bytes.

\section{Overview of the implementation}
The core of the LightScript implementation consists of three parts: 1) a top down operator precedence parser that is responsible for building the syntax tree, and identify which variables needs to be boxed on the heap for closures, 2) a compiler which translate the abstract syntax tree to a sequence of opcodes while keeping track of the stack depth, and 3) a stack-based virtual machine for executing the code.
Beside these core elements, the implementation also contain an API for embedding, and a library of standard functions.

The parser is a concrete implementation of the top down operator precedence parser for imperative laanguage, as described in Section~\ref{tdop-imp}, with the additional detail, that during the parsing, the parser keep track of which variable is defined and used in each function, such that this information can be used for scoping later on. 
The source code for the parser starts on page~\pageref{lightscript-parser}.
\index{Top down operator precedence parser}

\subsection{Compiler}

The core of the compiler is a function that compiles a node of the syntax tree, possibly calling itself recursively for the children.
As it is compiling to a stack-based virtual machine, the compilation itself can be quite simple/small, as functions and operators, just need to evaluate its parameters in a way that pushes the results to the stack, followed by doing the operation on the top elements of the stack.

As the activation records is also allocated on the stack, the compiler needs to keep track of the current stack depth, so whenever emitting a function that changes the stack depth, the stack depth variable also needs to be kept updated.

The abstract syntax tree does not distinguise between statements and expressions. Instead the compiler function takes a parameter which indicates whether the generated code is expected to push a result on the stack or not, and corresponding code will be generated. 

By having the integer for the abstract syntax tree node type match the virtual machine instruction, many of the compilation cases can be joined.


\subsection{Virtual Machine}
The virtual machine is stack-based in order to reduce the footprint of the compiler.
It is implemented with a single larger switch statement as it is running on top of JVM, as the JVM, does not support for references to labels, etc.
The instruction set is inspired by the JVM and calling conventions on i386, and is also product of the iterative development, such that new instructions are added, as they are needed by the compiler.
\index{Virtual machine}


\section{Language specification}
\index{Language specification!LightScript}
The language is mostly a subset of EcmaScript \cite{ecma-262}, and the description of the different parts of the languages is written in the same sequence as the EcmaScript standard, to make it easier to compare the two. The focus will on where LightScript differs from EcmaScript.
Scripts written for LightScript also runs unaltered in EcmaScript compliant interpreters, with af couple of extra functions defined within EcmaScript. On the other hand, EcmaScript may or may not run within LightScript, as LightScript is only a subset of EcmaScript.

The specification is stricter than the actual implementation, for example: the implementation does not distinguish between statements and expressions, and allows a statement everywhere an expression could be written, whereas the specification follows EcmaScript, and distinguishes the two.

Only a subset relatively small subset of EcmaScript is implemented: operators has been added as needed, meaning that rare operators has not yet been added. 
On the other hand, more interesting language aspects, such as exceptions and prototypical inheritance, have been implemented and tested, though they may not have been needed for the example programs or benchmarks.

The specification below follows the overall structure of the EcmaScript specification, to make it easier to compare the two.


\subsection{Lexical conventions}
The lexical conventions are slightly different from EcmaScript. 
Whitespaces are space, tab, carriage return and line feed. 
LightScript does not distinguish between whitespace and line terminators, and do not have automatic semicolon insertion.

Comments are started with two consecutive slashes \verb|//| and runs to the next newline character.

Keywords reserved by EcmaScript are also reserved by LightScript. The keywords currently used by LightScript are: {\tt catch do else for function if return this throw try var while}. This will be expanded in the next version of LightScript.

Identifiers start with a letter or an underscore, and continues with any combination of letters, underscores and digits. 
LightScript does not support escaped unicode sequences, but do accept utf-8 encoded. Non-letter unicode symbols with value larger than 127 are not supported. This allows a parsers to be implemented easier as they can just treat any 8-bit character with a value larger than 127 as a part of a unicode letter.

The punctuators in the current version of LightScript are: {\tt \verb|{| \verb|}| ( ) [ ] . ; , < > <= >= === !== + - * \% >> ! \&\& || ? : = += -=}. 
This will expand in the next version of LightScript where the remaining operators will be added, except for division as discussed in Section~\ref{division} on page~\pageref{division}.

String literals are always enclosed in double qoutation \verb|"|, and single quotation is not supported. It is possible to use backslash \verb|\| to escape quotation marks, backslashes and newline (\verb|"\n"| is the string containing a newline).

Integer literals are written as a sequence of digits, not starting with a zero, unless the number is zero. Only base 10 literals are supported.

Other literals are \verb|true| which translates to a value that has a true truth value, and \verb|false|, \verb|null| and \verb|undefined| which translates to a value that has a false truth value.

\subsection{Types}
LightScript has 5 builtin types: nil, string, number, array, and objects.

The nil type only has one value, which is referenced to as \verb|undefined|, \verb|null| or \verb|false|. 
Strings are immutable sequences of characters.
Numbers are 32 bit integers.
An array is a growable and mutable sequence of values, where the values can have any type.
Objects are mappings between names and values, where the name should be of the string type, and the value can be of any type. Objects can have another object prototype, where, if the lookup in the first object does not find a mapping, the name is then looked up in the prototype object.
The order of traversal of the object names/values, may be implementation dependent such that implementations may choose to implement them via hashtables or lists, depending on what makes most sense for the platform. This is different from EcmaScript, where the traversal is in the order the properties were added to the object.
\index{Prototypical inheritance}

\subsection{Execution contexts}

With each function call a new execution context / activation record is created. 
Variabled defined with the \verb|var| keyword are allocated on the current activation record. 
If a variable is not in the current functions activation record,
it is looked up in the lexical outer function, or if there is no outer function, the global scope.
This is the usual static scoping, where functions are the only way to make a scope closure.
\index{Scope}

\subsection{Expressions}

When a function is called as a property on an object, evaluation of \verb|this| within the function yields the object.  Identifiers are evaluated in the scope to yield a value. Literal values are just their value.

Array are initialised with square brackets \verb|[| $elem_1,\cdots,elem_n$ \verb|]|. Elements can be any expression, and are separated with commas (\verb|,|). 
Objects can similarly be initialised with curly brackets: \verb|{| 
$key_1: value_1, \cdots key_n: value_n$ \verb|}|, where the keys must be string literals, and values can be any expression.

Parenthesis can be used to group expressions together, for example: $2 * (3 + 4) \neq 2 * 3 + 4$

Objects and arrays can be subscripted with the bracket notation: $object$\verb|[|$key$\verb|]|, where $key$ can be be any expression that yields something that can be used as a subscript. The dot notation can be used as a shorthand for the case where $key$ is a string literal, such that $object$\verb|.|$name$ is equivalent to $object$\verb|["|$name$\verb|"]|.

The \verb|new| operator from JavaScript is not supported in LightScript, but instead objects can be initialised with \verb|{}|, or in case of inheritance, the \verb|clone| library function can be used.

Function calls are written as an expression followed by, a possibly empty, parenthesised argument list, e.g. $func$\verb|(|$arg_1,\cdots,arg_n$\verb|)|, where the arguments are separated by commas. 
A function written in LightScript, currently has a fixed number of arguments.

The postfix versions of increment/decrement are not supported, and the prefix versions should be used instead. The postfix operators has the effect of altering the variable, but returning the unaltered result, which can lead to difficult-to-read programs, and thus in the current version of LightScript, this is disencouraged by not having the postfix operators at all.

The implemented prefix operators are \verb|++|, \verb|--|, \verb|-|, and \verb|!|, which works as usual. \verb|delete|, \verb|typeof|, \verb|void| and \verb|~|, is not implemented in the current version, but may be added later on.

Implemented binary arithmetic operations are: multiplication \verb|*|, modulo \verb|%|, addition \verb|+|, subtraction \verb|-| and right shift \verb|>>|. These works only on numbers, except addition, that, if one of the parameters is not a number does string concatenation instead.  Division \label{division} is not implemented as \verb|/|, due to the semantic differences in integer and floating point division, but can instead be implemented as an integer division function, \verb|div(|$a,b$\verb|)|. The remaining shifting and bitwise operators, \verb|<<|, \verb|>>>|, \verb|&|, \verb%|%, \verb|^|, has not been needed, and thus not implemented yet, but will be added to the next version of LightScript.

Comparison operators are: \verb|<|, \verb|<=|, \verb|>|, \verb|>=|, \verb|!==|, \verb|===|, which works as usual. The equality operators does an actual comparison and not just a reference comparison. 
The type coerced equality operators from JavaScript \verb|!=| and \verb|==|, are omitted and should generally not be used \cite{javascriptnoeqeq} as they have some semantic issues, they are for example not transitive.

The current assignment operators supported by the language are: \verb|=|, \verb|+=| and \verb|-=|.
The remaining will be added in the next version.
The conditional operator \verb|? :| is supported. The comma operator \verb|,| is not supported, as that one generally is considered bad programming style \cite{crockford-web}.

\subsection{Statements}
Statements are separated by semicolon \verb|;|.
Blocks consist of a sequence of statments within curly brackets \verb|{|$\cdots$\verb|}|. This may for example be needed in conjunction with \verb|if| or \verb|function| declaration. Notice that in JavaScript and thus also LightScript, a block is not a scope limit. In LightScript, blocks are only allowed, where they could actually be needed, e.g. in conjunction with different the conditional/iteration statements, function declaration and try/catch.

The conditional and iteration statements supported by LightScript are: \verb|if|, \verb|do|$\cdots$\verb|while|, \verb|while|, and \verb|for|, which works similarly to JavaScript.

Functions can be exited with the \verb|return| statement, where the optional parameter to the return statement is returned.

LightScript does not support the \verb|with|, as this is considered bad programming style.

\verb|switch| statements, \verb|break|, \verb|continue| and labelled statements are not supported. In JavaScript the semantics of the switch statement are mostly syntactic sugar for a sequence of \verb|if|-statements combined with an anonymous variable, as the expressions of the \verb|case|-clauses are evaluated sequentially and then compared to the result of the expression in the switch clause.
These may be added in later versions of LightScript.

Exceptions are thrown with the \verb|throw| statements, which works similarly to JavaScript.
The \verb|try| statment is slightly different, as LightScript only supports the \verb|try|$\cdots$\verb|catch| version, and does not currently support \verb|finally| option.
LightScript also has slightly different scoping rules for the catch block, where the caught variable is a usual variable, where JavaScript is creating a new object in the scope chain only containing this variable. The motivation for this change is that it is a more consistent approach to scoping, where this would otherwise be a special case, requireing more code space, where at the same time, this only an incompatibilities if the variable in the catch-statment shadows another variable, whose value is used after the catch block, - which also should be avoided as that would lead to more difficult-to-read code.
\index{Exceptions}

\subsection{Function definitions}
Functions are defined using the \verb|function| keyword, followed by an optional function name, a list of parameters and the function body.
If the function name is specified, a variable with that name is assigned to the function.

The LightScript currently does not support a variable numbers of parameters, nor can the functions have properties.
This is going to be added in the next version.
Functions are first class objects, and can be passed around, and used as such. Application of functions are done with the usual $f$\verb|(|$\cdots$\verb|)|.

\subsection{Native LightScript objects and functions}
The current LightScript implementation only has a small standard library, with the purpose of being a proof of concept that functions can easily be added. The following functions and methods are implemented:

\paragraph{print(value)} Utility function printing a value to standard out.
\paragraph{gettype(value)} Returns a string representation of the type of the parameter, either ``object'', ``array'', ``number'', ``undefined'' or ``builtin''. This can be used instead of the \verb|typeof| operator, which in EcmaScript has some semantic issues.
\paragraph{parseint(str)} Parses a string as a base 10 integer, and return the integer result.
\paragraph{clone(parent)} Create a new object using the parameter as the prototype.
\paragraph{Array.push(elem)} Method of arrays, pushes an element to the end of the array.
\paragraph{Array.pop()} Pops an element from the end of the array and returns it.
\paragraph{Array.join(sep)} Join the elements of an array as strings, with separator between each neighbours.
\paragraph{Object.hasOwnProperty(name)} Property of prototype for objects, return whether the name, is actually a key in the current object. Used for determining whether a property is a part of the object, or its prototype.
\paragraph{*.length} A special property, indicating the length of an array or string, or the number of properties in an object.


% []subscript []array . {}hashtable {}block >> * %  ()function-call ()paren + - === !==  <= < >= > && || else in ?: = += -= var return ! ++ -- throw try catch function do-while while for if this undefined/null/false true "string" 123number



\section{Developer guide to embedding LightScript in Java}
To evaluate code with LightScript, the developer first has to instantiate a LightScript object, which keeps track of global values, loaded libraries, and internal compiler state. The constructor takes no parameters, so creating it is just:
\begin{lstlisting}
    LightScript lsContext = new LightScript();
\end{lstlisting}
This context can then be used to evaluate LightScript code, using the \verb|eval| method. This method either takes a string or an \verb|java.io.InputStream| as parameter, which is then read and executed:
\begin{lstlisting}
    lsContext.eval("print(\"Hello world \" + 17 * 42)");
    lsContext.eval(new FileInputStream(new File("myscript.js")));
\end{lstlisting}
Global variables of the context can be read and written with the \verb|get| and \verb|set| method, so for example:
\begin{lstlisting}
    lsContext.set("foo", new Integer(17));
    lsContext.eval("bar = foo + 25;");
    System.out.println(lsContext.get("bar");
\end{lstlisting}
would print \verb|42|.

\subsection{Adding native functions to the runtime}

A method of a Java object can be called from LightScript if the object implements the \verb|LightScriptFunction| interface, which defines an \verb|apply| method.
The interface is:
\lstinputlisting{../code/LightScript/LightScriptFunction.java}
So for example a function that returns the current number of milliseconds could be implemented as:
\begin{lstlisting}
class MillisecondsFunction implements LightScriptFunction {
    public Object apply(Object thisPtr, Object[] args, int argpos, 
                        int argcount) throws LightScriptException {
        return new Integer((int)System.currentTimeMillis());
    }
}
\end{lstlisting}

Adding a function to the runtime is just like adding any other variable,
via using the \verb|put| method of the LightScript object.
So using the function above to perform some timings in LightScript can be done as follows:
\begin{lstlisting}
    lsContext.set("timer",new MillisecondsFunction());
    lsContext.eval("begin = timer();"
                  +"for(i=0;i<1000000;++i);"
                  +"print(\"Time used: \" + (timer() - begin));");
\end{lstlisting}

When registrering several functions, it is more compact to join them via a dispatch, 
so a class implementing several functions could be implemented as follows:
\begin{lstlisting}
class FunctionLibrary implements LightScriptFunction {
    int id; // This tells which function the object represents
    public Object apply(Object thisPtr, Object[] args, int argpos, 
                        int argcount) throws LightScriptException {
        switch(id) {
            case 0: // integer division
                return new Integer(((Integer)args[argpos]).intValue()
                                  /((Integer)args[argpos+1]).intValue());
            case 1: // increment property i, not of superclass
                int i = ((Integer)((Hashtable)thisPtr).get("i")).intValue();
                ((Hashtable)thisPtr).put("i", new Integer(i + 1));
        }
        return null;
    }
    private FunctionLibrary(int id) { this.id = id; }
    public static void register(LightScript lsContext) {
        lsContext.set("div", new FunctionLibrary(0));
        lsContext.set("propinc", new FunctionLibrary(1));
    }
}
\end{lstlisting}
which could be used like:
\begin{lstlisting}
    FunctionLibrary.register(lsContext);
    lsContext.eval("obj = {}; obj.i = 1; obj.inc = propinc;"
                  +"while(obj.i < 10) {"
                  +"  print(div(42, obj.i));"
                  +"  obj.inc();"
                  +"}");
\end{lstlisting}

\subsection{Datatypes}
LightScript uses ordinary Java objects for most data.
Strings, stacks, tables, are the standard Java classes.
Boolean values are the constants \verb|LightScript.TRUE| and \verb|LightScript.FALSE|, instead of Java Booleans as that improves performance

LightScript objects are instances of \verb|java.lang.Hashtable|. If the lightscript object is cloned from another object, it is an instance of the \verb|LightScriptObject| class, which is subclass of \verb|java.lang.Hashtable|. LightScript objects have a constructor that corresponds to clone in Self, described in Section~\ref{survey-self}, and the parameter to the constructor is a LightScript object, either as a \verb|java.lang.Hashtable| or a \verb|LightScriptObject|. \verb|LightScriptObject| overloads the \verb|get| operator of the hashtable superclass, such that when the to key is not found in the current object, it does a lookup in the prototype from which the object was cloned.

Exceptions that can be thrown to/from LightScript are of the class \verb|LightScriptException|. This exception has a property \verb|value| that is the object that is thrown/caught within LightScript. The constructor just takes the value as an argument.

\section{Versions and future directions}
\index{Future works}
The LightScript version described above is version 1.0.426

The version number consist of a major version number, a minor version number and a revision number.
The major version number is incremented at major rewrites and redesign.
The minor version number is incremented with milestones and expansions of language/added functionality, it uses an even/uneven strategy, such that even minor versions gets bugfixes, and the uneven minor versions are development versions where the new features are added, i.e. 
the features intended for version 1.2 are implemented in versions 1.1.\emph{something} and when all of them is added, the minor version number increases to 1.2, where only bug fixes will be added.
The revision number correspond to the svn version, and is incremented on each commit.

The following is the roadmap of scheduled changes to LightScript version 1:
\begin{itemize}
\item[1.0]
Prototype for thesis and proof of concept.
Version 1.0 is the one used for the benchmarks and described throughout this report, unless otherwise mentioned. 
\item[1.2]
Expansion of language and standard library, more operators from EcmaScript are added,
and an additional fixed point number representation will be added. Better compatibility with EcmaScript type system.
\item[1.4]
Extra optional libraries to make the language more useful for practical applications.
\end{itemize}

\subsection{Roadmap towards version 1.2}
Where the previous parts of this chapter describes LightScript version 1.0, this section describes the most recent changes, and updates in the development branch, done after the report was written.
In the following is listed what have been done in version 1.1 and what needs to be done before version 1.2
\subsubsection{Implemented changes}
\begin{itemize}
\item Optimise code footprint, by reordering opcodes
\item Add support for fixed-point arithmetics
%To determine whether it is worthwhile needs an actual implementation. - this costed 2-3KB code footprint.
\end{itemize}
\subsubsection{Remaining tasks}
\begin{itemize}
\item Add more functions, operators, etc. 
\item Add postfix increment/decrement
\item Let functions support a variable number of arguments
%\item Let catch, and function-def behave as implicit \verb|var|-decl
\item Change of the implementation to make the it even more EcmaScript-like by relying on LightScript object class in Java, rather than standard Java classes, This costs a slightly larger code footprint, and also makes it slightly more complex to integrate with existing Java applications.
\item Walk through library specification, and add functions that does not add too large a foorprint
\item Add prototype object to functions
\item Improve virtual machine by joining common instruction pairs to single instructions (adding superinstructions)
\item Replace stack allocation instruction with automatic code to do this, based on metadata of the function object 
\item Add clean-up code when exiting a function, to improve garbage collection
\end{itemize}

\chapter{Benchmarks}
\label{benchmark}
\index{Benchmarks}

\section{Code footprint}
This section looks at the code footprint: first footprint estimates are compared for different scripting languages, then details on the footprint of LightScript is investigated, and finally the actual size of the library embedded in a minimal application is found.

\subsection{Comparison with other languages}
To compare the code footprint size across languages, I have added an estimate of the JAR file size. 
The estimate is done by making a zip archive of the non-obscurified class files,
trying to exclude class files that are part of extra libraries.
The motivation for this approach is to make the comparison more fair, as some of the languages have large GUI libraries,
which would count against them if we just looked at the JAR file. 
In addition, compilation of some of the languages is obscurified/optimised by default,
which would give those an advantage. So this approach should give a more fair comparison.
\index{JAR-file}

\subsubsection{Languages}
\label{codefootprint-languages}
The code size benchmark looks at the languages implemented in this project, Yolan and LightScript, at scripting languages for mobile devices, FScriptMe, Kahlua, Hecl, Simkin, and CellularBasic, and at some general scripting language implementations,  JScheme, and Rhino.

\index{FScriptME}
FScriptME \cite{fscriptme} is the mobile edition of femto-script, which ``is an extremely simple scripting language'' \cite{fscript}. 
Out of the box, it only supports strings and integers as data types -- no compound types -- which limits use somewhat, and it is still in beta, since 2002. 

\index{Lisp and Scheme!JScheme}
\index{Scheme|see{Lisp and Scheme}}
JScheme \cite{jscheme} is a small Scheme implementation. We benchmark an early version as later versions have a vastly larger code footprint. It depends on some reflection, and does therefore not run on Java Micro Edition, but is included as the implementation is compact, and may be changed to target mobile devices.

\index{Lua!Kahlua}
Kahlua \cite{kahlua} is an implementation of the Lua Virtual Machine for Java Micro Edition. 
The implementation requires CLDC-1.1 due to the use of floating point arithmetics, and does therefor not run on the lowest end mobile devices, which only supports CLDC-1.0.
Unlike the other languages, kahlua is not a full language interpreter, but only a virtual machine, so the the script cannot executed directly on the device, but needs to be compiled on another computer before being executed.

\index{Hecl}
Hecl \cite{hecl} seems to be \emph{the} major scripting language for mobile devices, or at least the one keep popping up in the top of most queries when searching for scripting languages for mobile devices.
It is very portable, with different editions running on CLDC-1.0, CLDC-1.1, Android, as applets and as usual applications.
It has lots of libraries targeting mobile devices, which in this comparison were removed from the zip file of class files, not to give languages with fewer libraries an advantage in the size comparison.
The language is a dialect of Tcl, and is simplified such that arithmetic operators, and the like, are prefix operators so expressions ends up a bit Lisp-like.

\index{Simkin}
Simkin \cite{simkin} is a scripting language for being embedded in XML, which also runs on mobile devices. It depends on kxml xml library, which is not included in the measured size. 

\index{CellularBasic}
CellularBasic \cite{cellularbasic} is a dialect of Qbasic, implemented for mobile devices. 
It includes a floating point support library which is not included in the measured size. 

\index{Rhino}
Rhino \cite{rhino} is a JavaScript implementation. This language is not designed for, nor does it run on, mobile devices. It is included as an example of an implementation of a usual non-mobile scripting language.

\subsubsection{Results}
The approximated JAR sizes of the scripting languages are:
\begin{center}
\begin{tabular}{|c|r|} \hline 
Yolan & 7K \\ \hline 
LightScript & 14K \\ \hline 
\end{tabular}
\begin{tabular}{|c|r|} \hline 
FScriptME & 17K \\ \hline 
Jscheme & 29K \\ \hline 
Kahlua & 39K \\ \hline 
Hecl & 54K \\ \hline 
Simkin & 81K \\ \hline 
CellularBasic & 83K \\ \hline 
Rhino & 397K \\ \hline 
\end{tabular}
\end{center}

The languages developed in this project smaller than other scripting languages for the platform. 
Yolan is approximately half the size of LightScript. 

\subsection{Details on the footprint of LightScript}
The sizes of the different part of the LightScript class is listed below.
Reduction is the reduction of the full class file when the mentioned part is left out. Alone is the size of the class file with everything else than the mentioned part left out. These numbers are different as some things are shared and some things cannot be left out when compiling the class file.

\begin{center} \begin{tabular}{|r|r|rl|} \hline
\multicolumn{2}{|r|}{Reduction} & \multicolumn{2}{|l|}{Alone}\\ \hline
Everything & 15030 & 17706 & \\ \hline
API & 645  & 3597  & \\ \hline
Tokeniser & 1261 & 4048 & \\ \hline
Parser & 2542 & 5850 & \\ \hline
Compiler & 5324 & 8413 & \\ \hline
Vm & 4589 & 7650 & \\ \hline
Parser+Tokeniser & 3825 & 7093 & \\ \hline
\end{tabular} \end{center}

\subsection{Optimised JAR-file footprint}
\index{JAR-file}
Previous sections have looked at comparable footprints for implementations by approximated JAR file size, and also at what parts contributes to the size of the LightScript class.
From a practical view it is also interesting to see the actual size of the optimised obscurified JAR-file of embedding the languages in a trivial host application.
The host application is a simple Midlet that adds a print function to the language, and includes a hello-world program.
The size of the entire application, including the embedded scripting language implementation is 5290 bytes for Yolan and 11342 bytes for LightScript. 

\section{Execution speed}
This section benchmarks the execution speed of the languages. 
In the following subsections, the languages that are benchmarked, and the actual benchmark programs are described, and finally the results of running the benchmarks are tabulated. 
%The source code for the benchmarks can be seen in appendix~\ref{benchmarksource}.

\subsection{Languages}
The benchmarks are run on those of the languages from Section~\ref{codefootprint-languages}, that have an approximated JAR size of less than 64K. They also run on two JavaScript interpreters: Rhino 1.6r7 and SpiderMonkey 1.7.0, which are described in Section~\ref{spidermonkey}, and are the default versions when installed on Ubuntu Linux.

\subsection{The benchmarks}
The benchmarks are the following:

\paragraph{Fibonacci:} Recursive calculation of the 30'th Fibonacci number
\paragraph{Loops:} Nested loops with counters, 10.000.000 iterations
\paragraph{Recursion:} Highly recursive benchmark, similar to recursive control-flow benchmark from \cite{sunspider, shootout}. Uses lots of stack space. On some of the languages where it fails, only the first part of it was implemented.
\paragraph{Sieve:} Simple implementation of Erasthones sieve - not implemented in languages which have already shown to be very slow in earlier benchmarks
\paragraph{For-in:} Nested loops across keys of a dictionary, 1.000.000 iterations - not implemented in languages which have already shown to be very slow in earlier benchmarks
\paragraph{Primes:} Simple primality test by looking at the remainders of division - not implemented in languages which have already shown to be very slow in earlier benchmarks
\paragraph{Exception:} Throw/catch 500.000 exceptions - only implemented for LightScript/JavaScript
\paragraph{Fannkuch:} Access-fannkuch benchmark from \cite{sunspider, shootout} - only implementd for LightScript/JavaScript

\subsection{Results}
The measurement of the performance of the different scripting languages are shown below. The timings are seconds per benchmark. $\bot$ indicates that the benchmark does not complete due to running out of stack space.

\begin{center} \begin{tabular}{|r|r|r|r|r|r|r|r|rr|} \hline 
& \multicolumn{2}{|l|}{Fibonacci} & \multicolumn{2}{|l|}{Recursion} & \multicolumn{2}{|l|}{For-in} & \multicolumn{2}{|l}{Exceptions} & \\
& & \multicolumn{2}{|l|}{Loops} & \multicolumn{2}{|l|}{Sieve} & \multicolumn{2}{|l|}{Primes} & \multicolumn{2}{|l|}{Fannkuch} \\
\hline Rhino       & 1.20 & 1.74 & 1.75   & 2.97 & 1.18 & 12.35 & 45.99 & 6.35 & \\ 
\hline SpiderMonkey& 1.28 & 1.71 & $\bot$ & 2.08 & 1.14 & 11.03 & 0.45  & 5.10 & \\ 
\hline LightScript & 1.37 & 3.45 & 2.35   & 1.19 & 0.57 & 11.70 & 0.65  & 11.15 & \\
\hline Yolan       & 1.47 & 2.23 & $\bot$ & 1.95 & 0.32 &  9.20 &  &  & \\
\hline Kahlua      & 2.13 & 1.18 & $\bot$ &  5.73 & 2.26 & 5.49 &  &  & \\ 
\hline JScheme    & 29.77 & 93.22 & $\bot$ & & & & & & \\ 
\hline FscriptME & 176.27 & 112.68& $\bot$ & & & & & & \\ 
\hline Hecl      & 207.96 & 47.21 & $\bot$ & & & & & & \\ 
\hline \end{tabular}
\end{center} 

\chapter{Discussion and future work}
\label{discussion}
\section{Performance}
It is interesting to see that Rhino, SpiderMonkey, LightScript, Yolan, and Kahlua is all within the same magnitude of speed, indicating that this is the speed you get with a simple interpreter for these kinds of scripting languages. Here it is also suprising that Rhino and SpiderMonkey is not much faster, as Rhino compile to, and loads Java classes at run time, and SpiderMonkey is written in C rather than Java, which allows for using more advanced implementation techniques.

Other observation are that Rhino is slow with exceptions, and that Kahlua seems to be fast with loops and slow with arrays. The last is probably due to that Kahlua implement arrays as hashtables, and loops in Lua has the integer sequence in the \verb|for|-construct, allowing \verb|for|-loops to be simpler to evaluate that in JavaScript, LightScript and Yolan, where the counter variable is explicit updated within the scripting language.

It is also interesting how similar in performance Yolan and LightScript are, even though they have very different evaluation strategy: Yolan is interpreted by traversing a syntax tree data structure, whereas LightScript runs on a stack-based virtual machine. 

Most of the scripting languages with a small code footprint is an order of magnitude slower than LightScript, Yolan, and Kahlua and the JavaScript implementations.
This may be due to inefficient implementation of variable access in JScheme, FScriptME and Hecl. Looking at the source code, JScheme and FScriptME variables are looked up in a linked list or hashtable at each access. Hecl has a more complex lookup mechanism with a stack of hashtables, but also employes some kind of caching.

\section{Size}

The scripting languages developed in this project has significantly smaller code footprint than other scripting languages for mobile Java devices.
Two reasons for this are: 1) the implementations have focused on code footprint from start to end, using techniques for writing compact code to a much higher degree than existing scripting language implementation for mobile Java devices, and 2) the parsers, which usually would take tens, or more, of kilobytes, has been reduced significantly: in case of Yolan this was done by having a trivial syntax, and in case of LightScript by optimising and using top down operator precedence parsing.

The size comparison even falls more favorable out, especially for LightScript, when taking the features of the languages into account:
The third language in size, FScriptME, is a very minimalistic language, that does not have builtin support for arrays, or objects, or higher-order functions, or exceptions, or anything like that, which accounts for its small size.
The next two languages, on place four and five in size, are JScheme and Kahlua,
have simple or no parser, due to having Lisp-like syntax or being just a virtual machine.

That the parser is likely to be a bottleneck can be seen in FScriptME, where the parser is 90\% of the implementation, in CellularBasic, where the source code of the lexer and parser is more than 100KB, and may also have be an influence on Hecl not supporting Tcl-like \verb|expr| with infix binary operators, but insted Hecl only has comparisons and arithemetic operators written in Lisp-like prefix notation which are simpler to write parsers for.

\section{Developed languages}
\subsection{Yolan}
Yolan does a good job having a tiny code footprint and decent performance, while being a scripting language with first class function, hashtables, easy embeddable, etc., and does a bad job trying to do anything else:
the dynamic scoping makes it unsuitable for developing larger applications, and the Lisp-like syntax will probably scare away most developers.
So the major use of this language is probably just to set a bar for how small a code footprint a high-level scripting language can have.

While it has an interesting result, code size wise, there will probably not be any further developments in this language, other than it served as a stepping stone towards LightScript.

\subsection{LightScript}
LightScript is much more featurefull and useful than Yolan, while this comes by having twice the footprint of Yolan, it is still small compared to other scripting languages targeting mobile devices. .
The JavaScript/EcmaScript like syntax and semantics should make it much more approachable for other developers, while still having expressive features like supporting closures and higher-order functions.

There is a tradeoff between EcmaScript compliance and size/performance. 
One of those is the joining of \verb|false|, \verb|null| and \verb|undefined|, and not needing the boolean type.
As the overall size and performance of LightScript were better than expected,
that optimisation-tradeoff is probably worth undoing to get better semantics, 
but only an implementation and actual benchmark will show. 

LightScript is definitely a language I will use for developing mobile applications in the future, so the project has at least been successful by making a tool in that direction.

\section{Future development of LightScript}
\index{Future works}
The next development with LightScript is toward version 1.2, which is described in the LightScript chapter, and after that publishing it, and expanding the library as discussed below.
On the long term, other possible milestones are optimisation of the byte code, porting LightScript to embedded C, and better development tools in shape of prettyprinting and linting.

\subsection{Making it public}
LightScript will be released as open source software. 
Just releasing the source, is not enought to make it really usable for others: documentation, and examples, are also of major importance, and there also has to be an awareness about the exisitance of the language, which needs some work on publishing information on the project, including an informative wikipedia page, and press release/posting of articles on news sites related to programming languages and mobile development.
The website \url{http://www.lightscript.net/}, will serve as the main site, and a small dummy page is already put up.

\subsection{User interface and other optional libraries}
Currently LightScript needs custom Java functions to be added for doing anything useful, as there are no input library for input/output.
As the language implementation stabilises, the next step is to create a library which can optionally be included within the application.
A lot of standard functionality, such as cryptography, http-networking, storage, etc.,  can relatively easily merged from the platform, or existing open source libraries. 
Other libraries may require further consideration, one major task here is integration of a graphical user interface with LightScript, as on this point, there are major differences between the platform on which LightScript runs, both within APIs on platforms, and also of actual platform capabilities.

\subsubsection{User interface}
Additional libraries for LightScript is scheduled for version 1.4, and the major design task will here be the user interface. 
Issues are very varying or limited resolutions and and input methods, ranging from screen size of 96x65 pixels, up to full desktops, and input methods from simple phone keypad, to touch-input-only, to multi touch, to regular computers.

A solution that will be interesting to pursue is in the direction of zooming interfaces, as these able to scale down to small screens.
Prototypes within this project has has also gone in the direction of zooming interfaces, though they have yet to be integrated with the scripting language, and have achived maturity to become a part of this report.
\index{Zooming user interfaces}

\subsubsection{Other optional libraries}

Much interactions happens via web, so a simple function for getting and parsing web pages will be practical for enabling LightScript as a tool for mobile mashups would be needed. This will be a simple heuristic html parser mapping the XML-tree to JsonML\footnote{JsonML is an embedding of XML in JSON, somewhat similar to SXML in the Scheme} \cite{jsonml}, which can then easily be interacted with in LightScript.
The access to http-connections are supported within CLDC/1.0 and CLDC/1.1, as well as larger Java platforms, and just needs to be wrapped.

When making applications that may handle the users private data, it should be secured, which is why support for simple cryptography should be added. There already exist a good open source library for mobile cryptography \cite{bouncycastle} where a couple of ciphers can be extracted and added as optional library in LightScript.

\subsection{Optimising the bytecode}

A way to optimise the execution, and reduce the memeory usage of compiled programs, would be to optimise the byte codes, by joining common code sequences. Which byte codes to combine can be determined by using grammar based compression techniques on generated code, and create new codes from the founcd dictionary. 
This reduce the memory usage, as the generated codebecomes shorter, and increases the performance as the joined codes only need a single dispatch for the new code. The cost is a larger larger code footprint due to the new byte codes. If this is to be implemented, it probably has to wait until there are more code written within LightScript, as a larger amount of code is needed for better generation of dictionaries.

\subsection{Embedded implementation}

Another direction with the development of LightScript is the implementation on non-Java platforms.
Embedded C is very different from Mobile Java: the importance of the run time memory usage and code footprint is reversed, as embedded devices often have larger built in flash ROM, than working memory.

The first target platform for an embedded C implementation will be the Mindstorm NXT, which has 64K of RAM, and 256K of ROM.
\index{Mindstorm NXT}
An optimisation here is to use 16bit tagged pointers/small integers rather than 32bit, to save memory. 

An interesting implementation aspect to study is the effect to enforce unique strings. This will cost approximately additional 3 bytes per string, and string creation will be more expensive, but at the same time, there will be no copies of identical strings, which may save significant space, and string comparison is changed to pointer comparision, which is much faster.

\subsection{Lint and prettyprinter}

Another future target is to improve the development environment for LightScript.
As the parser does not support error checking, currently the easiest way to develop is to use an EcmaScript compliant development platform, and stay within the limits of the LightScript subset.
A LightScript linting program would be a practical tool, as this would also be able to catch if the programmer goes outside the LightScript subset of EcmaScript.
Currently much of this can be caught with debugging in the current version LightScript, but a real linter may also warn about bad usages, and have more helpful messages to the developer.

Another development tool, possibly integrateable with the linter is a prettyprinter, which is both practival to enforce coding conventions, to keep source readable when several programmers are working on the same project, and it may also go beyond just prettyprinting and transform some unsupported EcmaScript features into LightScript.

\chapter{Conclusion}
\label{conclusion}
\index{Conclusion}
Two new scripting languages has emerged out of a series of prototypes.

Yolan is a minimalistic scripting language with first class functions and Lisp like syntax. This language is a proof of concept that the code footprint cost of an embeddable scripting language for Mobile Java applications, can be kept low, in this case approximately 5 KB.

LightScript has also been created, and while it has a larger footprint than Yolan, it still smaller than other languages. LightScript is more developer friendly, being a subset of JavaScript, and has also more features, such as an object system with inheritance and support for exceptions.
The language and its implementation can be of practical use, and will be developed further, after this thesis.

Yolan and LightScript are pushing the edge of small scripting language implementation on mobile Java enabled devices, by having smaller code footprint, being fast, and having advanced language features, compared to other scripting language on mobile devices.


%\chapter{Introduction to scripting \\ -- a user guide}
%\input{language/userguide}
%

\newpage
\index{Bibliography}
\addcontentsline{toc}{chapter}{Bibliography}
\bibliography{bibliography}
\bibliographystyle{alpha}

\appendix

%\input{../code/bench/marks.tex}

\chapter{Source code of the Yolan class}
\index{Yolan!source code}
\lstinputlisting{../code/Yolan/src/Yolan.java}

\chapter{Source code of the LightScript class}
\index{LightScript!source code}
\lstinputlisting{../code/LightScript/LightScript.javapp}


\newpage
\addcontentsline{toc}{chapter}{Index}
\printindex

\end{document}

